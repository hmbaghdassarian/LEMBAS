{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd794ff6-277a-4975-923f-6e8172c47f93",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fde630b-45bd-4dfa-9f53-c75f189614c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2745576/3158502584.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0463, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "\n",
    "#import saveSimulations\n",
    "\n",
    "inputAmplitude = 3\n",
    "projectionAmplitude = 1.2\n",
    "\n",
    "#Setup optimizer\n",
    "batchSize = 10\n",
    "MoAFactor = 0.1\n",
    "spectralFactor = 1e-5\n",
    "maxIter = 5000\n",
    "noiseLevel = 10\n",
    "stateLossFactor = 1e-4\n",
    "L2 = 1e-6\n",
    "lr = 2e-3\n",
    "\n",
    "seed = 49#888\n",
    "if seed:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "seed_counter = 0 # !!used for addNoiseToAllGradients and steadyStateLoss -- += 1 per training loop, and seed input is seed + seed_counter\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "lembas_path = '/nobackup/users/hmbaghda/Software/avlant_LEMBASGPU'\n",
    "\n",
    "def import_from_path(name, path):\n",
    "    spec = importlib.util.spec_from_file_location(name, path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "bionetwork = import_from_path('bionetwork', os.path.join(lembas_path, 'bionetwork.py'))\n",
    "plotting = import_from_path('plotting', os.path.join(lembas_path, 'plotting.py'))\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#Load network\n",
    "networkList, nodeNames, modeOfAction = bionetwork.loadNetwork(os.path.join(lembas_path, 'data', 'macrophage-Model.tsv'))\n",
    "annotation = pandas.read_csv(os.path.join(lembas_path, 'data', 'macrophage-Annotation.tsv'), sep='\\t')\n",
    "uniprot2gene = dict(zip(annotation['code'], annotation['name']))\n",
    "bionetParams = bionetwork.trainingParameters(targetSteps = 100, maxSteps = 150, expFactor= 50, tolerance = 1e-5, leak=0.01)\n",
    "\n",
    "inName = annotation.loc[annotation['ligand'],'code'].values\n",
    "outName = annotation.loc[annotation['TF'],'code'].values\n",
    "inName = numpy.intersect1d(nodeNames, inName)\n",
    "outName = numpy.intersect1d(nodeNames, outName)\n",
    "outNameGene = [uniprot2gene[x] for x in outName]\n",
    "nodeNameGene = [uniprot2gene[x] for x in nodeNames]\n",
    "\n",
    "ligandInput = pandas.read_csv(os.path.join(lembas_path, 'data', 'macrophage-Ligands.tsv'), sep='\\t', low_memory=False, index_col=0)\n",
    "TFOutput = pandas.read_csv(os.path.join(lembas_path, 'data', 'macrophage-TFs.tsv'), sep='\\t', low_memory=False, index_col=0)\n",
    "\n",
    "#Subset input and output to intersecting nodes\n",
    "inName = ligandInput.columns.values\n",
    "outName = TFOutput.columns.values\n",
    "\n",
    "# doesnt change anything\n",
    "inName = numpy.intersect1d(nodeNames, inName)\n",
    "outName = numpy.intersect1d(nodeNames, outName)\n",
    "\n",
    "# map from uniprot ID to gene name \n",
    "inNameGene = [uniprot2gene[x] for x in inName]\n",
    "outNameGene = [uniprot2gene[x] for x in outName]\n",
    "\n",
    "# c\n",
    "ligandInput = ligandInput.loc[:,inName] # conditions x ligand (values are binary of presence or absence)\n",
    "TFOutput = TFOutput.loc[:,outName] # conditions x TFs (values are TF activity score)\n",
    "sampleName = ligandInput.index.values\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "model = bionetwork.model(networkList, nodeNames, modeOfAction, inputAmplitude, projectionAmplitude, inName, outName, bionetParams, seed = seed, device = device, activationFunction = 'MML')\n",
    "model.inputLayer.weights.requires_grad = False\n",
    "model.network.preScaleWeights()\n",
    "# model.setDevice(device)\n",
    "# model = model.to(device)\n",
    "\n",
    "spectralCapacity = model.network.param['spectralTarget']\n",
    "\n",
    "X = torch.tensor(ligandInput.values.copy(), dtype=torch.float32, device = device)\n",
    "Y = torch.tensor(TFOutput.values, dtype=torch.float32, device = device)\n",
    "# X = X.to(device)\n",
    "# Y = Y.to(device)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, weight_decay=0)\n",
    "resetState = optimizer.state.copy()\n",
    "\n",
    "mLoss = criterion(torch.mean(Y, dim=0) * torch.ones(Y.shape, device = Y.device), Y)\n",
    "print(mLoss)\n",
    "\n",
    "\n",
    "stats = plotting.initProgressObject(maxIter)\n",
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12faf2b6-7e6c-4522-bf86-e49d9898d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "e = 0\n",
    "curLr = bionetwork.oneCycle(e, maxIter, maxHeight = lr, startHeight=lr/10, endHeight=1e-6, peak = 1000)\n",
    "\n",
    "optimizer.param_groups[0]['lr'] = curLr\n",
    "\n",
    "curLoss = []\n",
    "curEig = []\n",
    "numpy.random.seed(seed + e)\n",
    "trainloader = numpy.array_split(numpy.random.permutation(N), numpy.ceil(N/batchSize).astype(int))\n",
    "\n",
    "dataIndex = trainloader[0]\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "dataIn = X[dataIndex, :].view(len(dataIndex), X.shape[1])\n",
    "dataOut = Y[dataIndex, :].view(len(dataIndex), Y.shape[1])\n",
    "\n",
    "Yin = model.inputLayer(dataIn)\n",
    "# print(seed + counter)\n",
    "torch.manual_seed(seed + counter)\n",
    "torch.cuda.manual_seed(seed + counter)\n",
    "network_noise = torch.randn(Yin.shape, device = Yin.device)\n",
    "Yin = Yin + noiseLevel * curLr * network_noise\n",
    "YhatFull = model.network(Yin)\n",
    "Yhat = model.projectionLayer(YhatFull)\n",
    "\n",
    "fitLoss = criterion(dataOut, Yhat)\n",
    "\n",
    "signConstraint = model.network.signRegularization(MoAFactor)\n",
    "ligandConstraint = 1e-5 * torch.sum(torch.square(model.network.bias[model.inputLayer.nodeOrder]))\n",
    "stabilityLoss, spectralRadius = model.network.steadyStateLoss(YhatFull.detach(), spectralFactor, topNvalues = 10, seed = seed + counter)\n",
    "stateLoss = model.applyUniformLoss(curLr * stateLossFactor, YhatFull)\n",
    "regLoss = model.L2Reg(L2)\n",
    "\n",
    "loss = fitLoss + signConstraint + ligandConstraint + regLoss + stabilityLoss + stateLoss\n",
    "loss.backward()\n",
    "model.addNoiseToAllGradients(1e-9, seed = seed + counter)\n",
    "optimizer.step()\n",
    "\n",
    "counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac9880-4897-49d5-aaa3-ccd079f2421a",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a72671c-28c9-4562-9625-ec631a5d5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Next, we want to see whether scLEMBAS can capture the heterogeneity of cell responses upon ligand exposure. \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "# lembas_path = '/nobackup/users/hmbaghda/Software/LEMBAS'\n",
    "lembas_path = '/nobackup/users/hmbaghda/Software/avlant_LEMBASGPU'\n",
    "\n",
    "sclembas_path = '/home/hmbaghda/Projects/scLEMBAS/scLEMBAS'\n",
    "sys.path.insert(1, os.path.join(sclembas_path))\n",
    "from model.bionetwork import format_network, SignalingModel\n",
    "import utilities as utils\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "n_cores = 12\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(n_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(n_cores)\n",
    "\n",
    "seed = 49#888\n",
    "if seed:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "utils.set_seeds(seed = seed)\n",
    "data_path = '/nobackup/users/hmbaghda/scLEMBAS/analysis'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# # Set Parameters\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "projection_amplitude_in = 3\n",
    "projection_amplitude_out = 1.2\n",
    "\n",
    "# learning rate parameters\n",
    "max_iter = 5000\n",
    "learning_rate = 2e-3\n",
    "\n",
    "# other training parameters\n",
    "batch_size = 10\n",
    "noise_level = 10\n",
    "gradient_noise_level = 1e-9\n",
    "\n",
    "# regularization and spectral radius params\n",
    "param_lambda_L2 = 1e-6\n",
    "moa_lambda_L1 = 0.1 # MoAFactor\n",
    "ligand_lambda_L2 = 1e-5\n",
    "uniform_lambda_L2 = 1e-4\n",
    "uniform_max = 1/projection_amplitude_out\n",
    "spectral_loss_factor = 1e-5\n",
    "target_spectral_radius = 0.8\n",
    "n_probes_spectral = 5\n",
    "power_steps_spectral = 50\n",
    "subset_n_spectral = 10\n",
    "\n",
    "\n",
    "# # Build the Model\n",
    "\n",
    "# Load Data:\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# prior knowledge signaling network\n",
    "net = pd.read_csv(os.path.join(lembas_path, 'data', 'macrophage-Model.tsv'), sep = '\\t', index_col = False)\n",
    "\n",
    "# ligand input and TF output\n",
    "ligand_input = pd.read_csv(os.path.join(lembas_path, 'data', 'macrophage-Ligands.tsv'), sep='\\t', low_memory=False, index_col=0)\n",
    "tf_output = pd.read_csv(os.path.join(lembas_path, 'data', 'macrophage-TFs.tsv'), sep='\\t', low_memory=False, index_col=0)\n",
    "\n",
    "\n",
    "# Let's see what the signaling network looks like:\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "stimulation_label = 'stimulation'\n",
    "inhibition_label = 'inhibition'\n",
    "weight_label = 'mode_of_action'\n",
    "source_label = 'source'\n",
    "target_label = 'target'\n",
    "\n",
    "net[[source_label, target_label, stimulation_label, inhibition_label]].head()\n",
    "\n",
    "\n",
    "# Let's format it to fit with the necessary inputs to the SignalingModel:\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "net = format_network(net, weight_label = weight_label, stimulation_label = stimulation_label, inhibition_label = inhibition_label)\n",
    "net[[source_label, target_label, weight_label, stimulation_label, inhibition_label]].head()\n",
    "\n",
    "\n",
    "# Next, let's initialize the model and format the inputs/outputs for running the model:\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "training_parameters = {'targetSteps': 100, 'maxSteps': 150, 'expFactor':50, 'tolerance': 1e-5, 'leak':1e-2}\n",
    "mod = SignalingModel(net = net,\n",
    "                     X_in = ligand_input,\n",
    "                     y_out = tf_output, \n",
    "                     projection_amplitude_in = projection_amplitude_in, projection_amplitude_out = projection_amplitude_out,\n",
    "                     weight_label = weight_label, source_label = source_label, target_label = target_label,\n",
    "                     bionet_params = training_parameters, \n",
    "                     dtype = torch.float32, device = device, seed = seed)\n",
    "\n",
    "X_in = mod.df_to_tensor(mod.X_in)\n",
    "y_out = mod.df_to_tensor(mod.y_out)\n",
    "\n",
    "\n",
    "# The ligand input, after filtering for nodes in the network, looks like this:\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "mod.X_in.head()\n",
    "\n",
    "\n",
    "# The TF activity output, after filtering for nodes in the network, looks like this:\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "mod.y_out.head()\n",
    "\n",
    "\n",
    "# The forward pass looks like this:\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# X_in = mod.df_to_tensor(mod.X_in) # ligand inputs\n",
    "# X_full = mod.input_layer(X_in) # ligand inputs in signaling network\n",
    "# Y_full = mod.signaling_network(X_full) # signaling network weights\n",
    "# Y_hat = mod.output_layer(Y_full) # TF outputs of signaling network\n",
    "\n",
    "\n",
    "# # Set up the Model for Training:\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# model setup\n",
    "mod.input_layer.weights.requires_grad = False # don't learn scaling factors for the ligand input concentrations\n",
    "mod.signaling_network.prescale_weights(target_radius = target_spectral_radius) # spectral radius\n",
    "\n",
    "# parameters\n",
    "spectral_capacity = mod.signaling_network.training_params['spectralTarget']\n",
    "\n",
    "# inputs\n",
    "X_in = mod.df_to_tensor(mod.X_in)\n",
    "y_out = mod.df_to_tensor(mod.y_out)\n",
    "\n",
    "# loss and optimizer\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(mod.parameters(), lr=1, weight_decay=0)\n",
    "reset_state = optimizer.state.copy()\n",
    "\n",
    "# mean TF (across samples) loss\n",
    "mean_loss = loss_fn(torch.mean(y_out, dim=0) * torch.ones(y_out.shape, device = y_out.device), y_out)\n",
    "\n",
    "stats = utils.initialize_progress(max_iter)\n",
    "n_samples = X_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee38db1-eb9d-46e7-a1db-d74c964e41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "# set learning rate\n",
    "cur_lr = utils.get_lr(e, max_iter, max_height = learning_rate, start_height=learning_rate/10, end_height=1e-6, peak = 1000)\n",
    "optimizer.param_groups[0]['lr'] = cur_lr\n",
    "\n",
    "cur_loss = []\n",
    "cur_eig = []\n",
    "\n",
    "np.random.seed(seed + e)\n",
    "train_loader = np.array_split(np.random.permutation(n_samples), np.ceil(n_samples/batch_size).astype(int))\n",
    "    \n",
    "    # iterate through batches\n",
    "data_index = train_loader[0]\n",
    "mod.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# get batch I/O\n",
    "batch_size_iter = len(data_index)\n",
    "X_in_ = X_in[data_index, :].view(batch_size_iter, X_in.shape[1])\n",
    "y_out_ = y_out[data_index, :].view(batch_size_iter, y_out.shape[1])\n",
    "\n",
    "# forward pass\n",
    "X_full = mod.input_layer(X_in_) # transform to full network with ligand input concentrations\n",
    "utils.set_seeds(mod.seed + mod._gradient_seed_counter)\n",
    "network_noise = torch.randn(X_full.shape, device = X_full.device)\n",
    "X_full = X_full + (noise_level * cur_lr * network_noise) # randomly add noise to signaling network input, makes model more robust\n",
    "Y_full = mod.signaling_network(X_full) # train signaling network weights\n",
    "Y_hat = mod.output_layer(Y_full)\n",
    "\n",
    "# get prediction loss\n",
    "fit_loss = loss_fn(y_out_, Y_hat)\n",
    "\n",
    "# get regularization losses\n",
    "sign_reg = mod.signaling_network.sign_regularization(lambda_L1 = moa_lambda_L1) # incorrect MoA\n",
    "ligand_reg = mod.ligand_regularization(lambda_L2 = ligand_lambda_L2) # ligand biases\n",
    "stability_loss, spectral_radius = mod.signaling_network.get_SS_loss(Y_full = Y_full.detach(), spectral_loss_factor = spectral_loss_factor,\n",
    "                                                                    subset_n = subset_n_spectral, n_probes = n_probes_spectral, \n",
    "                                                                    power_steps = power_steps_spectral)\n",
    "uniform_reg = mod.uniform_regularization(lambda_L2 = uniform_lambda_L2*cur_lr, Y_full = Y_full, \n",
    "                                         target_min = 0, target_max = uniform_max) # uniform distribution\n",
    "param_reg = mod.L2_reg(param_lambda_L2) # all model weights and signaling network biases\n",
    "\n",
    "total_loss = fit_loss + sign_reg + ligand_reg + param_reg + stability_loss + uniform_reg\n",
    "total_loss.backward()\n",
    "mod.add_gradient_noise(noise_level = gradient_noise_level)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6050bfed-8c65-47e5-a31a-09113e34b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594d3191-52d5-4bc7-b370-eee1dce015ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.equal(X_in, X):\n",
    "    print('X_in unequal')\n",
    "if not torch.equal(X_full, Yin):\n",
    "    print('X_full unequal')\n",
    "if not torch.equal(Y_full, YhatFull):\n",
    "    print('Y_full unequal')\n",
    "    if not torch.allclose(Y_full, YhatFull, atol = 1e-7):\n",
    "        print('Y_full not close')\n",
    "if not torch.equal(Yhat, Y_hat):\n",
    "    print('Yhat unequal')\n",
    "    if not torch.allclose(Yhat, Y_hat, atol = 1e-7):\n",
    "        print('Yhat not close')\n",
    "\n",
    "model_parameters = list(model.parameters())\n",
    "for i, param in enumerate(list(mod.parameters())):\n",
    "    if not torch.equal(model_parameters[i], param):\n",
    "        print('Param ' + str(i) + ' unequal')\n",
    "        if not torch.allclose(model_parameters[i], param, atol = 1e-9):\n",
    "            print('Param ' + str(i) + ' not close')\n",
    "    if param.requires_grad and param.grad is not None and not torch.equal(model_parameters[i].grad, param.grad):\n",
    "        print('Param grad' + str(i) + ' unequal')\n",
    "        if param.requires_grad and param.grad is not None and not torch.allclose(model_parameters[i].grad, param.grad, \n",
    "                                                                     atol = 1e-14):\n",
    "            print('Param grad' + str(i) + ' not close')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scLEMBAS]",
   "language": "python",
   "name": "conda-env-scLEMBAS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
