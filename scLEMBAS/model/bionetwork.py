from typing import Dict, List, Union, Annotated
from annotated_types import Ge

import pandas as pd
import numpy as np 
import scipy
from scipy.sparse.linalg import eigs
#from scipy.linalg import norm
from scipy.linalg import eig

import torch
import torch.nn as nn

def format_network(net: pd.DataFrame, 
                   weight_label: str = 'mode_of_action', 
                   stimulation_label: str = 'stimulation', 
                   inhibition_label: str = 'inhibition') -> pd.DataFrame:
    """Formats the standard network file format to that needed by `SignalingModel.parse_network`

    Parameters
    ----------
    net : pd.DataFrame
        signaling network adjacency list with the following columns:
            - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0.1). Exclude non-interacting (0) nodes. 
            - `stimulation_label`: binary whether an interaction is stimulating (1) or [not stimultaing or unknown] (0)
            - `inhibition_label`: binary whether an interaction is inhibiting (1) or [not inhibiting or unknown] (0)
    weight_label : str, optional
        converts `stimulation_label` and `inhibition_label` to a single column of stimulating (1), inhibiting (-1), or
        unknown (0.1), by default 'mode_of_action'
    stimulation_label : str, optional
        column name of stimulating interactions, see `net`, by default 'stimulation'
    inhibition_label : str, optional
        column name of inhibitory interactions, see `net`, by default 'inhibition'

    Returns
    -------
    formatted_net : pd.DataFrame
        the same dataframe with the additional `weight_label` column
    """
    if net[(net[stimulation_label] == 1) & (net[inhibition_label] == 1)].shape[0] > 0:
        raise ValueError('An interaction can either be stimulating (1,0), inhibition (0,1) or unknown (0,0)')
    
    formatted_net = net.copy()
    formatted_net[weight_label] = np.zeros(net.shape[0])
    formatted_net.loc[formatted_net[stimulation_label] == 1, weight_label] = 1
    formatted_net.loc[formatted_net[inhibition_label] == 1, weight_label] = -1
    
    #ensuring that lack of known MOA does not imply lack of representation in scipy.sparse.find(A)
    formatted_net[weight_label] = formatted_net[weight_label].replace(0, 0.1)
    formatted_net[weight_label] = formatted_net[weight_label].replace(np.nan, 0.1)

    return formatted_net

class ProjectInput(nn.Module):
    """Generate all nodes for the signaling network and linearly scale input ligand values by learned parameters."""
    def __init__(self, node_idx_map: Dict[str, int], input_labels: np.array, projection_amplitude: Union[int, float] = 1, dtype: torch.dtype=torch.float32):
        """Initialization method.

        Parameters
        ----------
        node_idx_map : Dict[str, int]
            a dictionary mapping node labels (str) to the node index (float)
            generated by `SignalingModel.parse_network`
        input_labels : np.array
            names of the input nodes (ligands) from net
        projection_amplitude : Union[int, float]
            value with which to initialize learned linear scaling parameters, by default 1. (if turn require_grad = False for this layer, this is still applied 
            simply as a constant linear scalar in each forward pass)
        dtype : torch.dtype, optional
            datatype to store values in torch, by default torch.float32
        """
        super().__init__()

        self.projection_amplitude = projection_amplitude
        self.size_out = len(node_idx_map) # number of nodes total in prior knowledge network
        self.input_node_order = torch.tensor([node_idx_map[x] for x in input_labels]) # idx representation of inputs
        weights = self.projection_amplitude * torch.ones(len(input_labels), dtype=dtype)
        self.weights = nn.Parameter(weights)
        
    def forward(self, X_in):
        """Learn the weights for the input ligands to the signaling network"""
        X_full = torch.zeros([X_in.shape[0],  self.size_out], dtype=X_in.dtype, device=X_in.device) # shape of (samples x total nodes in network)
        X_full[:, self.input_node_order] = self.weights * X_in # only modify those nodes that are part of the input (ligands)
        return X_full
    
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        Here, this pushes learned parameters towards `projection_amplitude` 
        
        Parameters
        ----------
        lambda_2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
        
        Returns
        -------
        projection_L2 : torch.Tensor
            the regularization term
        """
        # if removed the `- self.projection_amplitude `part, would force weights to 0, thus shrinking ligand inputs
        projection_L2 = lambda_L2 * torch.sum(torch.square(self.weights - self.projection_amplitude))  
        return projection_L2
    
    def set_device(self, device):
        self.input_node_order = self.input_node_order.to(device)

class BioNet(nn.Module):
    def __init__(self, edge_list: np.array, 
                 edge_weights: np.array, 
                 network_size: int, 
                 bionet_params: Dict[str, float], 
                 activation_function: str = 'MML', 
                 dtype: torch.dtype=torch.float32):
        """Initialization method.

        Parameters
        ----------
        edge_list : np.array
            a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
            second row represents the indices for the source node. net.shape[0] is the total # of interactions
            output from  `SignalingModel.parse_network` 
        edge_weights : np.array
            a (1, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
            second row is a boolean of whether the interactions are inhibiting
            output from  `SignalingModel.parse_network`
        network_size : int
            the number of nodes in the network
        bionet_params : Dict[str, float]
            training parameters for the model
            see `SignalingModel.set_training_parameters`
        activation_function : str, optional
            _description_, by default 'MML'
        dtype : torch.dtype, optional
           datatype to store values in torch, by default torch.float32
        """
        super().__init__()
        self.training_params = bionet_params

        self.network_size_in = network_size
        self.network_size_out = network_size
        self.edge_list = (torch.tensor(edge_list[0, :]), torch.tensor(edge_list[1, :]))
        self.edge_weights = torch.tensor(edge_weights)
        self.type = dtype
        #H0 = 0.5 * torch.rand((network_size, 1), dtype=dtype)
        #H0 = torch.zeros((network_size, 1), dtype=dtype)

        # initialize weights and biases
        weightValues, bias = self.initializeWeights()
        self.mask = self.makeMask(self.edge_list, network_size)
        weights = torch.zeros(self.mask.shape, dtype = dtype)
        weights[self.edge_list] = weightValues
        
        self.edge_weightsValues, self.edge_weightsMask = self.makeMOAMask()

        self.weights = nn.Parameter(weights)
        self.bias = nn.Parameter(bias)
        #self.H0 = nn.Parameter(H0)
             
        #self.step = forwardNetworkGPU.FFnet(edge_list, network_size, network_size)
        
        if activation_function == 'MML':
            self.activation = activationFunctions.MMLactivation
            self.delta = activationFunctions.MMLDeltaActivation
            self.oneStepDeltaActivationFactor = activationFunctions.MMLoneStepDeltaActivationFactor
        elif activation_function == 'leakyRelu':
            self.activation = activationFunctions.leakyReLUActivation
            self.delta = activationFunctions.leakyReLUDeltaActivation
            self.oneStepDeltaActivationFactor = activationFunctions.leakyReLUoneStepDeltaActivationFactor     
        elif activation_function == 'sigmoid':
            self.activation = activationFunctions.sigmoidActivation
            self.delta = activationFunctions.sigmoidDeltaActivation
            self.oneStepDeltaActivationFactor = activationFunctions.sigmoidOneStepDeltaActivationFactor
        else:
            print('No activation function!')
            
    def makeMOAMask(self):
        MOAsigned = self.edge_weights[0, :].type(torch.long) - self.edge_weights[1, :].type(torch.long) #1=activation -1=inhibition, 0=unknown
        weights = torch.zeros(self.network_size_out, self.network_size_in, dtype=torch.long)
        weights[self.edge_list] = MOAsigned
        MOAmask = weights == 0
        return weights, MOAmask

    def makeMask(self, edge_list, network_size):
        weights = torch.zeros(network_size, network_size, dtype=bool)
        weights[self.edge_list] = True
        weights = torch.logical_not(weights)
        return weights

    def setDevice(self, device):
        #self.A = self.A.to(device)
        self.edge_weights = self.edge_weights.to(device)
        self.mask = self.mask.to(device)
        self.edge_weightsValues = self.edge_weightsValues.to(device)
        self.edge_weightsMask = self.edge_weightsMask.to(device)
        #self.step.setDevice(device)
        #self.edge_list[0] = self.edge_list[0].to(device)
        #self.edge_list[1] = self.edge_list[1].to(device)
        
    def forward(self, x):
        self.applySparsity()
        tol = self.training_params['tolerance']
        iterations = self.training_params['maxSteps']
        
        condition = torch.tensor(True, device=x.device)
        transposedX = x.T
        transposedX = transposedX + self.bias
        new = torch.zeros_like(transposedX)
        
        #allSteps = []
        for i in range(iterations):
            old = new
            new = torch.mm(self.weights, new) #self.step(tmp)
            new = new + transposedX         
            new = self.activation(new, self.training_params['leak']) #self.step(tmp)
            
            if (i % 10 == 0) and (i > 20):
                diff = torch.max(torch.abs(new - old))    
                #diff = torch.max(torch.abs(new - allSteps[i-1]))          
                passTolerance = diff.lt(tol)
                if passTolerance == condition:
                    #allSteps.extend([new.unsqueeze(0)] * (iterations-i))
                    break
            #allSteps.append(new.unsqueeze(0))
        #allSteps = torch.cat(allSteps, axis=0)
        #allSteps = allSteps.permute([0, 2, 1])
        steadyState = new.T
        return steadyState #, allSteps
        #return bionetworkFunction.apply(x, self.weights, self.bias, self.A, self.edge_list, self.training_params, self.activation, self.delta)


    def L2Reg(self, L2):
        #L2 = torch.tensor(L2, dtype = self.weights.dtype, device = self.weights.device)
        biasLoss = L2 * torch.sum(torch.square(self.bias))
        weightLoss = L2 * torch.sum(torch.square(self.weights))     
        #biasLoss = 0.1 * torch.sum(torch.abs(self.bias))
        #weightLoss = 0.1 * torch.sum(torch.abs(self.weights))
        return L2 * (biasLoss + weightLoss)

    def getWeight(self, nodeNames, source, target):
        self.A.data = self.weights.detach().numpy()
        locationSource = numpy.argwhere(numpy.isin(nodeNames, source))[0]
        locationTarget = numpy.argwhere(numpy.isin(nodeNames, target))[0]
        weight = self.A[locationTarget, locationSource][0]
        return weight

class SignalingModel(torch.nn.Module):
    """Constructs the signaling network based RNN."""
    DEFAULT_TRAINING_PARAMETERS = {'targetSteps': 100, 'maxSteps': 300, 'expFactor': 20, 'leak': 0.01, 'tolerance': 1e-5}
    
    def __init__(self, net: pd.DataFrame, X_in: pd.DataFrame, y_out: pd.DataFrame,
                 projection_amplitude: Union[int, float] = 1, projection_factor: float,
                 ban_list: List[str] = None, weight_label: str = 'mode_of_action', 
                 source_label: str = 'source', target_label: str = 'target', 
                bionet_params: Dict[str, float] = None , 
                 activation_function: str='MML', dtype: torch.dtype=torch.float32, device: str = 'cpu'):
        """Parse the signaling network and build the model layers.

        Parameters
        ----------
        net: pd.DataFrame
            signaling network adjacency list with the following columns:
                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1). Exclude non-interacting (0) nodes. 
                - `source_label`: source node column name
                - `target_label`: target node column name
        X_in : pd.DataFrame
            input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). 
        y_out : pd.DataFrame
            output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF. 
        ban_list : List[str], optional
            a list of signaling network nodes to disregard, by default None
        projection_amplitude : Union[int, float]
            value with which to scale ligand inputs by, by default 1 (see `ProjectInput` for details, can also be tuned as a learned parameter in the model)
        projection_factor : float
            _description_
        bionet_params : Dict[str, float], optional
            training parameters for the model, by default None
        activation_function : str, optional
            _description_, by default 'MML'
        dtype : torch.dtype, optional
            datatype to store values in torch, by default torch.float32
        device : str
            whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
        """
        super().__init__()
        self.dtype = dtype
        self.device = device

        edge_list, node_labels, edge_weights = self.parse_network(net, ban_list, weight_label, source_label, target_label)
        if not bionet_params:
            bionet_params = self.DEFAULT_TRAINING_PARAMETERS.copy()
        else:
            bionet_params = self.set_training_parameters(**bionet_params)

        # filter for nodes in the network, sorting by node_labels order
        self.X_in = X_in.loc[:, np.intersect1d(X_in.columns.values, node_labels)]
        self.y_out = y_out.loc[:, np.intersect1d(y_out.columns.values, node_labels)]
        self.input_labels = self.X_in.columns.values
        self.output_labels = self.y_out.columns.values

        # define model layers 
        self.input_layer = ProjectInput(self.node_idx_map, self.input_labels, projection_amplitude, self.dtype)
        self.signaling_network = BioNet(edge_list, edge_weights, size = len(node_labels), bionet_params = bionet_params, 
                                        activation_function = activation_function, dtype = self.dtype)

    def parse_network(self, net: pd.DataFrame, ban_list: List[str] = None, 
                 weight_label: str = 'mode_of_action', source_label: str = 'source', target_label: str = 'target'):
        """Parse adjacency network . Adapted from LEMBAS `loadNetwork` and `makeNetworkList`.
    
        Parameters
        ----------
        net: pd.DataFrame
            signaling network adjacency list with the following columns:
                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0). Exclude non-interacting (0)
                nodes. 
                - `source_label`: source node column name
                - `target_label`: target node column name
        ban_list : List[str], optional
            a list of signaling network nodes to disregard, by default None
    
        Returns
        -------
        edge_list : np.array
            a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
            second row represents the indices for the source node. net.shape[0] is the total # of interactions
        node_labels : list
            a list of the network nodes in the same order as the indices
        edge_weights : np.array
            a (1, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
            second row is a boolean of whether the interactions are inhibiting
        """
        if not ban_list:
            ban_list = []
        if sorted(net[weight_label].unique()) != [-1, 0.1, 1]:
            raise ValueError(weight_label + ' values must be 1 or -1')
        
        net = net[~ net[source_label].isin(ban_list)]
        net = net[~ net[target_label].isin(ban_list)]
    
        # create an edge list with node incides
        node_labels = sorted(pd.concat([net[source_label], net[target_label]]).unique())
        self.node_idx_map = {idx: node_name for node_name, idx in enumerate(node_labels)}
        
        source_indices = net[source_label].map(self.node_idx_map).values
        target_indices = net[target_label].map(self.node_idx_map).values

        # # get edge list
        # edge_list = np.array((target_indices, source_indices))
        # edge_weights = net[weight_label].values
        # get edge list *ordered by source-target node index*
        n_nodes = len(node_labels)
        A = scipy.sparse.csr_matrix((net[weight_label].values, (source_indices, target_indices)), shape=(n_nodes, n_nodes)) # calculate adjacency matrix
        source_indices, target_indices, edge_weights = scipy.sparse.find(A) # re-orders adjacency list by index
        edge_list = np.array((target_indices, source_indices))
    
        return edge_list, node_labels, edge_weights

    def df_to_tensor(self, df: pd.DataFrame):
        """Converts a pandas dataframe to the appropriate torch.tensor"""
        return torch.tensor(df.values.copy(), dtype=self.dtype).to(self.device)

    def set_training_parameters(self, **attributes):
        """Set the parameters for training the model. Overrides default parameters with attributes if specified.
        Adapted from LEMBAS `trainingParameters`
    
        Parameters
        ----------
        attributes : dict
            keys are parameter names and values are parameter value
        """
        #set defaults
        default_parameters = self.DEFAULT_TRAINING_PARAMETERS.copy()
        allowed_params = list(default_parameters.keys()) + ['spectralTarget']
    
        params = {**default_parameters, **attributes}
        if 'spectralTarget' not in params.keys():
            params['spectralTarget'] = np.exp(np.log(params['tolerance'])/params['targetSteps'])
    
        params = {k: v for k,v in params.items() if k in allowed_params}
    
        return params

    # def forward(self, X_in):
    #     X_full = self.inputLayer(X_in) # input ligand weights
    #     fullY = self.network(X_full)
    #     Yhat = self.projectionLayer(fullY)
    #     return Yhat, fullY
