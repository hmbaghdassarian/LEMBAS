<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>API - LEMBAS</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "API";
        var mkdocs_page_input_path = "api.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> LEMBAS
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../macrophage_example/">Tutorial</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">API</a>
    <ul class="current">
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">LEMBAS</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">API</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/hmbaghdassarian/LEMBAS/edit/master/docs/api.md">Edit on hmbaghdassarian/LEMBAS</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">



<a id="LEMBAS"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h2 id="LEMBAS.io" class="doc doc-heading">
          <code>io</code>


</h2>

  <div class="doc doc-contents ">
  
      <p>Read and write python objects.</p>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="LEMBAS.io.read_pickled_object" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">read_pickled_object</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Read an object as a pickled file.</p>
<h5 id="LEMBAS.io.read_pickled_object--parameters">Parameters</h5>
<p>file_name : str
    'full/path/to/file.pickle'</p>
<h5 id="LEMBAS.io.read_pickled_object--returns">Returns</h5>
<p>pickled_object
    the pickled object</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/io.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">read_pickled_object</span><span class="p">(</span><span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Read an object as a pickled file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    file_name : str</span>
<span class="sd">        &#39;full/path/to/file.pickle&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pickled_object</span>
<span class="sd">        the pickled object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
        <span class="n">pickled_object</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pickled_object</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.io.write_pickled_object" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">write_pickled_object</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Save an object as a pickled file.</p>
<h5 id="LEMBAS.io.write_pickled_object--parameters">Parameters</h5>
<p>object : Any
    object to save
file_name : str
    'full/path/to/file.pickle'</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/io.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">write_pickled_object</span><span class="p">(</span><span class="nb">object</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save an object as a pickled file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    object : Any</span>
<span class="sd">        object to save</span>
<span class="sd">    file_name : str</span>
<span class="sd">        &#39;full/path/to/file.pickle&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;.&#39;</span> <span class="ow">in</span> <span class="n">file_name</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
        <span class="n">extensions</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">suffixes</span><span class="p">)</span>
        <span class="n">file_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">extensions</span><span class="p">,</span> <span class="s1">&#39;.pickle&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">file_name</span> <span class="o">=</span> <span class="n">file_name</span> <span class="o">+</span> <span class="s1">&#39;.pickle&#39;</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">handle</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="LEMBAS.model" class="doc doc-heading">
          <code>model</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-module">



<h3 id="LEMBAS.model.activation_functions" class="doc doc-heading">
          <code>activation_functions</code>


</h3>

  <div class="doc doc-contents ">
  
      <p>Defines various activations functions to be used in neural net.</p>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.MML_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">MML_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the output of the Michaelis-Menten function</p>
<h6 id="LEMBAS.model.activation_functions.MML_activation--parameters">Parameters</h6>
<p>x : torch.Tensor
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU</p>
<h6 id="LEMBAS.model.activation_functions.MML_activation--returns">Returns</h6>
<p>fx : torch.Tensor
    a vector of output values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">MML_activation</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">leak</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the output of the Michaelis-Menten function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fx : torch.Tensor</span>
<span class="sd">        a vector of output values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="nb">input</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">leak</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">shifted_x</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">fx</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">shifted_x</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">gated_x</span> <span class="o">=</span> <span class="n">fx</span> <span class="o">+</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">mask</span> <span class="c1">#prevents division by 0 issue on next line</span>
    <span class="n">right_values</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">shifted_x</span><span class="p">,</span> <span class="n">gated_x</span><span class="p">)</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">*</span> <span class="p">(</span><span class="n">fx</span> <span class="o">-</span> <span class="n">right_values</span><span class="p">)</span> <span class="o">+</span> <span class="n">right_values</span> <span class="c1">#-fx trick from relu</span>
    <span class="k">return</span> <span class="n">fx</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.MML_delta_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">MML_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the derivative of the Michaelis-Menten function</p>
<h6 id="LEMBAS.model.activation_functions.MML_delta_activation--parameters">Parameters</h6>
<p>x : torch.Tensor
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU</p>
<h6 id="LEMBAS.model.activation_functions.MML_delta_activation--returns">Returns</h6>
<p>y : torch.Tensor
    a vector of output derivative values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">MML_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">leak</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the derivative of the Michaelis-Menten function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y : torch.Tensor</span>
<span class="sd">        a vector of output derivative values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask1</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1">#derivative = 1 if nothing else is stated</span>

    <span class="n">mask2</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">right_values</span> <span class="o">=</span> <span class="mf">0.25</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># add psuedocount bc x = 0 will creat NaN</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">mask2</span> <span class="o">*</span> <span class="n">right_values</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">leak</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask1</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.MML_onestepdelta_activation_factor" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">MML_onestepdelta_activation_factor</span><span class="p">(</span><span class="n">Y_full</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Adjusts weights for linearization in the spectral radius. </p>
<p>Note that this will only work for monotonic functions</p>
<h6 id="LEMBAS.model.activation_functions.MML_onestepdelta_activation_factor--parameters">Parameters</h6>
<p>Y_full : torch.Tensor
    <em>description</em>
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</p>
<h6 id="LEMBAS.model.activation_functions.MML_onestepdelta_activation_factor--returns">Returns</h6>
<p>y : torch.Tensor
    <em>description</em></p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">MML_onestepdelta_activation_factor</span><span class="p">(</span><span class="n">Y_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">leak</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adjusts weights for linearization in the spectral radius. </span>

<span class="sd">    Note that this will only work for monotonic functions</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    Y_full : torch.Tensor</span>
<span class="sd">        _description_</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y : torch.Tensor</span>
<span class="sd">        _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">Y_full</span><span class="p">)</span>
    <span class="n">piece1</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">piece3</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">safe_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y_full</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.9999</span><span class="p">)</span>
    <span class="n">right_values</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">safe_x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">piece3</span> <span class="o">*</span> <span class="n">right_values</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">leak</span><span class="p">)</span> <span class="o">*</span> <span class="n">piece1</span>  
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.leakyReLU_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">leakyReLU_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the output of the leaky ReLU function</p>
<h6 id="LEMBAS.model.activation_functions.leakyReLU_activation--parameters">Parameters</h6>
<p>x : Iterable[Union[float, int]]
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</p>
<h6 id="LEMBAS.model.activation_functions.leakyReLU_activation--returns">Returns</h6>
<p>fx
    a vector of output values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">leakyReLU_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the output of the leaky ReLU function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fx</span>
<span class="sd">        a vector of output values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">fx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">fx</span> <span class="o">*</span> <span class="n">leak</span><span class="p">,</span> <span class="n">fx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fx</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.leakyReLU_delta_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">leakyReLU_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the derivative of the leaky ReLU function</p>
<h6 id="LEMBAS.model.activation_functions.leakyReLU_delta_activation--parameters">Parameters</h6>
<p>x : Iterable[Union[float, int]]
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</p>
<h6 id="LEMBAS.model.activation_functions.leakyReLU_delta_activation--returns">Returns</h6>
<p>y : Iterable[Union[float, int]]
    a vector of output derivative values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">leakyReLU_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the derivative of the leaky ReLU function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of output derivative values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#derivative = 1 if nothing else is stated</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">leak</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1">#let derivative be 0.01 at x=0</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.sigmoid_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sigmoid_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the output of the sigmoid function</p>
<h6 id="LEMBAS.model.activation_functions.sigmoid_activation--parameters">Parameters</h6>
<p>x : Iterable[Union[float, int]]
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</p>
<h6 id="LEMBAS.model.activation_functions.sigmoid_activation--returns">Returns</h6>
<p>fx
    a vector of output values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sigmoid_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the output of the sigmoid function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fx</span>
<span class="sd">        a vector of output values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">#leak is not used for sigmoid_</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">fx</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">fx</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.activation_functions.sigmoid_delta_activation" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sigmoid_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Returns the derivative of the sigmoid function</p>
<h6 id="LEMBAS.model.activation_functions.sigmoid_delta_activation--parameters">Parameters</h6>
<p>x : Iterable[Union[float, int]]
    a vector of input values
leak : Union[float, int], optional
    parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</p>
<h6 id="LEMBAS.model.activation_functions.sigmoid_delta_activation--returns">Returns</h6>
<p>y : Iterable[Union[float, int]]
    a vector of output derivative values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/activation_functions.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sigmoid_delta_activation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the derivative of the sigmoid function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of input values</span>
<span class="sd">    leak : Union[float, int], optional</span>
<span class="sd">        parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y : Iterable[Union[float, int]]</span>
<span class="sd">        a vector of output derivative values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid_activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_activation</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="LEMBAS.model.bionetwork" class="doc doc-heading">
          <code>bionetwork</code>


</h3>

  <div class="doc doc-contents ">
  
      <p>Defines the various layers in the SignalingModel RNN.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="LEMBAS.model.bionetwork.BioNet" class="doc doc-heading">
          <code>BioNet</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.Module">Module</span></code></p>

  
      <p>Builds the RNN on the signaling network topology.</p>

            <details class="quote">
              <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BioNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds the RNN on the signaling network topology.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_list</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
                 <span class="n">edge_MOA</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
                 <span class="n">n_network_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                 <span class="n">bionet_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> 
                 <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;MML&#39;</span><span class="p">,</span> 
                 <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> 
                <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">888</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        edge_list : np.array</span>
<span class="sd">            a (2, net.shape[0]) array where the first row represents the indices for the target node and the </span>
<span class="sd">            second row represents the indices for the source node. net.shape[0] is the total # of interactions</span>
<span class="sd">            output from  `SignalingModel.parse_network` </span>
<span class="sd">        edge_MOA : np.array</span>
<span class="sd">            a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the </span>
<span class="sd">            second row is a boolean of whether the interactions are inhibiting</span>
<span class="sd">            output from  `SignalingModel.parse_network`</span>
<span class="sd">        n_network_nodes : int</span>
<span class="sd">            the number of nodes in the network</span>
<span class="sd">        bionet_params : Dict[str, float]</span>
<span class="sd">            training parameters for the model</span>
<span class="sd">            see `SignalingModel.set_training_parameters`</span>
<span class="sd">        activation_function : str, optional</span>
<span class="sd">            RNN activation function, by default &#39;MML&#39;</span>
<span class="sd">            options include:</span>
<span class="sd">                - &#39;MML&#39;: Michaelis-Menten-like</span>
<span class="sd">                - &#39;leaky_relu&#39;: Leaky ReLU</span>
<span class="sd">                - &#39;sigmoid&#39;: sigmoid </span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">           datatype to store values in torch, by default torch.float32</span>
<span class="sd">        device : str</span>
<span class="sd">            whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">        seed : int</span>
<span class="sd">            random seed for torch and numpy operations, by default 888</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="o">=</span> <span class="n">bionet_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span> <span class="o">=</span> <span class="n">n_network_nodes</span>
        <span class="c1"># TODO: delete these _in _out?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span> <span class="o">=</span> <span class="n">n_network_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_out</span> <span class="o">=</span> <span class="n">n_network_nodes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span> <span class="o">=</span> <span class="p">(</span><span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">),</span> 
                          <span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_MOA</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># initialize weights and biases</span>
        <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights_MOA</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_mask_MOA</span><span class="p">()</span> <span class="c1"># mechanism of action </span>

        <span class="c1"># activation function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;activation&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;delta&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onestepdelta_activation_factor</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;onestepdelta&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">initialize_weight_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the RNN weight_values for all interactions in the signaling network.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        weight_values : torch.Tensor</span>
<span class="sd">            a torch.Tensor with randomly initialized values for each signaling network interaction</span>
<span class="sd">        bias : torch.Tensor</span>
<span class="sd">            a torch.Tensor with randomly initialized values for each signaling network node</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">network_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># the target nodes receiving an edge</span>
        <span class="n">n_interactions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">network_targets</span><span class="p">)</span>

        <span class="n">set_seeds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">weight_values</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_interactions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">weight_values</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]]</span> <span class="o">=</span> <span class="o">-</span><span class="n">weight_values</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]]</span> <span class="c1"># make those that are inhibiting negative</span>

        <span class="n">bias</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">nt_idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">network_targets</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">weight_values</span><span class="p">[</span><span class="n">network_targets</span> <span class="o">==</span> <span class="n">nt_idx</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">):</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">nt_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">weight_values</span><span class="p">,</span> <span class="n">bias</span>

    <span class="k">def</span> <span class="nf">make_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates a mask for adjacency matrix for non-interacting nodes.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        weights_mask : torch.Tensor</span>
<span class="sd">            a boolean adjacency matrix of all nodes in the signaling network, masking (True) interactions that are not present</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">weights_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency list format (targets (rows)--&gt; sources (columns))</span>
        <span class="n">weights_mask</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># if interaction is present, do not mask</span>
        <span class="n">weights_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">weights_mask</span><span class="p">)</span> <span class="c1"># make non-interacting edges False and vice-vesa</span>
        <span class="k">return</span> <span class="n">weights_mask</span>

    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes weights and masks for interacting nodes and mechanism of action.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        weights : torch.Tensor</span>
<span class="sd">            a torch.Tensor adjacency matrix with randomly initialized values for each signaling network interaction</span>
<span class="sd">        bias : torch.Tensor</span>
<span class="sd">            a torch.Tensor with randomly initialized values for each signaling network node</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">weight_values</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weight_values</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_mask</span><span class="p">()</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency matrix</span>
        <span class="n">weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_values</span>

        <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>

    <span class="k">def</span> <span class="nf">make_mask_MOA</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates mask (and weights) for adjacency matrix for non-interacting nodes AND nodes were mode of action (stimulating/inhibiting) </span>
<span class="sd">        is unknown.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        weights_MOA : torch.Tensor</span>
<span class="sd">            an adjacency matrix of all nodes in the signaling network, with activating interactions set to 1, inhibiting interactions set </span>
<span class="sd">            to -1, and interactions that do not exist or have an unknown mechanism of action (stimulating/inhibiting) set to 0</span>
<span class="sd">        mask_MOA : torch.Tensor</span>
<span class="sd">            a boolean adjacency matrix of all nodes in the signaling network, with interactions that do not exist or have an unknown </span>
<span class="sd">            mechanism of action masked (True)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">signed_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="c1">#1=activation -1=inhibition, 0=unknown</span>
        <span class="n">weights_MOA</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency matrix</span>
        <span class="n">weights_MOA</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">signed_MOA</span>
        <span class="n">mask_MOA</span> <span class="o">=</span> <span class="n">weights_MOA</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">weights_MOA</span><span class="p">,</span> <span class="n">mask_MOA</span>

    <span class="k">def</span> <span class="nf">prescale_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_radius</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Scale weights according to spectral radius</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        target_radius : float, optional</span>
<span class="sd">            _description_, by default 0.8</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">A</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">eigen_value</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">eigs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># first eigen value</span>
        <span class="n">spectral_radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eigen_value</span><span class="p">)</span>

        <span class="n">factor</span> <span class="o">=</span> <span class="n">target_radius</span><span class="o">/</span><span class="n">spectral_radius</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">factor</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Learn the edeg weights within the signaling network topology.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_full : torch.Tensor</span>
<span class="sd">            the linearly scaled ligand inputs. Shape is (samples x network nodes). Output of ProjectInput.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Y_full :  torch.Tensor</span>
<span class="sd">            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="c1"># fill non-interacting edges with 0</span>

        <span class="n">X_bias</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="c1"># this is the bias with the projection_amplitude included</span>
        <span class="n">X_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X_bias</span><span class="p">)</span> <span class="c1">#initialize all values at 0</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;max_steps&#39;</span><span class="p">]):</span> <span class="c1"># like an RNN, updating from previous time step</span>
            <span class="n">X_old</span> <span class="o">=</span> <span class="n">X_new</span>
            <span class="n">X_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">X_new</span><span class="p">)</span> <span class="c1"># scale matrix by edge weights</span>
            <span class="n">X_new</span> <span class="o">=</span> <span class="n">X_new</span> <span class="o">+</span> <span class="n">X_bias</span>  <span class="c1"># add original values and bias       </span>
            <span class="n">X_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;leak&#39;</span><span class="p">])</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">):</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X_new</span> <span class="o">-</span> <span class="n">X_old</span><span class="p">))</span>    
                <span class="k">if</span> <span class="n">diff</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;tolerance&#39;</span><span class="p">]):</span>
                    <span class="k">break</span>

        <span class="n">Y_full</span> <span class="o">=</span> <span class="n">X_new</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">Y_full</span>

    <span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bionet_L2 : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bias_loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span>
        <span class="n">weight_loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>

        <span class="n">bionet_L2</span> <span class="o">=</span> <span class="n">bias_loss</span> <span class="o">+</span> <span class="n">weight_loss</span>
        <span class="k">return</span> <span class="n">bionet_L2</span>

    <span class="k">def</span> <span class="nf">get_sign_mistmatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Identifies edge weights in network that have a sign that does not agree</span>
<span class="sd">        with the known mode of action.</span>

<span class="sd">        Mode of action: stimulating interactions are expected to have positive weights and inhibiting interactions</span>
<span class="sd">        are expected to have negative weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        sign_mismatch : torch.Tensor</span>
<span class="sd">            a binary adjacency matrix of all nodes in the signaling network, where values are 1 if they do not </span>
<span class="sd">            match the mode of action and 0 if they match the mode of action or have an unknown mode of action</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_MOA</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> 
        <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="n">sign_mismatch</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_MOA</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># do not penalize sign mismatches of unknown interactions</span>

        <span class="k">return</span> <span class="n">sign_mismatch</span>

    <span class="k">def</span> <span class="nf">count_sign_mismatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Counts total sign mismatches identified in `get_sign_mistmatch`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_sign_mismatches : float</span>
<span class="sd">            the total number of sign mismatches at `iter`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_sign_mismatches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_sign_mistmatch</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">n_sign_mismatches</span>

    <span class="k">def</span> <span class="nf">sign_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L1</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L1 regularization term for the neural network parameters that </span>
<span class="sd">        do not fit the mechanism of action (i.e., negative weights for stimulating interactions or positive weights for inhibiting interactions).</span>
<span class="sd">        Only penalizes sign mismatches of known MOA.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_L1 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lambda_L1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_L1</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sign_mistmatch</span><span class="p">()</span> <span class="c1"># will not penalize sign mismatches of unknown interactions</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">sign_mismatch</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="c1"># def get_sign_mistmatch_edge_list(self):</span>
    <span class="c1">#     &quot;&quot;&quot;Same as `get_sign_mistmatch`, but converts to coordinates corresponding to `edge_list`</span>

    <span class="c1">#     Returns</span>
    <span class="c1">#     -------</span>
    <span class="c1">#     sign_mismatch : torch.Tensor</span>
    <span class="c1">#         a binary vector corresponding to coordinates in `edge_list`, where values are 1 if they do not </span>
    <span class="c1">#         match the mode of action and 0 if they match the mode of action or have an unknown mode of action</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     sign_mismatch = self.get_sign_mistmatch()</span>

    <span class="c1">#     # violations = sign_mismatch[self.edge_list] # 1 for interactions in edge list that mismatch, 0 otherwise</span>
    <span class="c1">#     # activation_mismatch = torch.logical_and(violations, self.edge_MOA[0])</span>
    <span class="c1">#     # inhibition_mismatch = torch.logical_and(violations, self.edge_MOA[1])</span>
    <span class="c1">#     # all_mismatch = torch.logical_or(activation_mismatch, inhibition_mismatch)</span>

    <span class="c1">#     sign_mismatch_edge = sign_mismatch[self.edge_list] # 1 for interactions in edge list that mismatch, 0 otherwise</span>

    <span class="c1">#     return sign_mismatch_edge</span>

    <span class="k">def</span> <span class="nf">get_SS_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">spectral_loss_factor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">subset_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Y_full : torch.Tensor</span>
<span class="sd">            output of the forward pass</span>
<span class="sd">            ensure to run `torch.Tensor.detach` method prior to inputting so that gradient calculations are not effected</span>
<span class="sd">        spectral_loss_factor : float</span>
<span class="sd">            _description_</span>
<span class="sd">        subset_n : int, optional</span>
<span class="sd">            _description_, by default 10</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        _type_</span>
<span class="sd">            _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spectral_loss_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">spectral_loss_factor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">exp_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;exp_factor&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span><span class="p">)</span>
        <span class="n">selected_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:</span><span class="n">subset_n</span><span class="p">]</span>

        <span class="n">SS_deviation</span><span class="p">,</span> <span class="n">aprox_spectral_radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_SS_deviation</span><span class="p">(</span><span class="n">Y_full</span><span class="p">[</span><span class="n">selected_values</span><span class="p">,:],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>        
        <span class="n">spectral_radius_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">exp_factor</span><span class="o">*</span><span class="p">(</span><span class="n">aprox_spectral_radius</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]))</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">spectral_radius_factor</span> <span class="o">*</span> <span class="n">SS_deviation</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">SS_deviation</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">spectral_loss_factor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">aprox_spectral_radius</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aprox_spectral_radius</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># new seed each time this (and _get_SS_deviation) is called</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">aprox_spectral_radius</span>

    <span class="k">def</span> <span class="nf">_get_SS_deviation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_full_sub</span><span class="p">,</span> <span class="n">n_probes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">power_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">):</span>
        <span class="n">x_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onestepdelta_activation_factor</span><span class="p">(</span><span class="n">Y_full_sub</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;leak&#39;</span><span class="p">])</span>     
        <span class="n">x_prime</span> <span class="o">=</span> <span class="n">x_prime</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="n">x_prime</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
            <span class="n">set_seeds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">Y_full_sub</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y_full_sub</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_probes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full_sub</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full_sub</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">power_steps</span><span class="p">):</span>
            <span class="n">new</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">new</span><span class="p">)</span>

        <span class="n">SS_deviation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">aprox_spectral_radius</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">SS_deviation</span><span class="p">)</span><span class="o">/</span><span class="n">power_steps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">SS_deviation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">SS_deviation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">SS_deviation</span><span class="p">)</span><span class="o">/</span><span class="n">power_steps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">SS_deviation</span><span class="p">,</span> <span class="n">aprox_spectral_radius</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.L2_reg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for the neural network parameters.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.L2_reg--parameters">Parameters</h6>
<p>lambda_2 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.BioNet.L2_reg--returns">Returns</h6>
<p>bionet_L2 : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    bionet_L2 : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bias_loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span>
    <span class="n">weight_loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>

    <span class="n">bionet_L2</span> <span class="o">=</span> <span class="n">bias_loss</span> <span class="o">+</span> <span class="n">weight_loss</span>
    <span class="k">return</span> <span class="n">bionet_L2</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">edge_list</span><span class="p">,</span> <span class="n">edge_MOA</span><span class="p">,</span> <span class="n">n_network_nodes</span><span class="p">,</span> <span class="n">bionet_params</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="s1">&#39;MML&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Initialization method.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.__init__--parameters">Parameters</h6>
<p>edge_list : np.array
    a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
    second row represents the indices for the source node. net.shape[0] is the total # of interactions
    output from  <code>SignalingModel.parse_network</code> 
edge_MOA : np.array
    a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
    second row is a boolean of whether the interactions are inhibiting
    output from  <code>SignalingModel.parse_network</code>
n_network_nodes : int
    the number of nodes in the network
bionet_params : Dict[str, float]
    training parameters for the model
    see <code>SignalingModel.set_training_parameters</code>
activation_function : str, optional
    RNN activation function, by default 'MML'
    options include:
        - 'MML': Michaelis-Menten-like
        - 'leaky_relu': Leaky ReLU
        - 'sigmoid': sigmoid 
dtype : torch.dtype, optional
   datatype to store values in torch, by default torch.float32
device : str
    whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
seed : int
    random seed for torch and numpy operations, by default 888</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_list</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
             <span class="n">edge_MOA</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> 
             <span class="n">n_network_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
             <span class="n">bionet_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> 
             <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;MML&#39;</span><span class="p">,</span> 
             <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
            <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> 
            <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">888</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge_list : np.array</span>
<span class="sd">        a (2, net.shape[0]) array where the first row represents the indices for the target node and the </span>
<span class="sd">        second row represents the indices for the source node. net.shape[0] is the total # of interactions</span>
<span class="sd">        output from  `SignalingModel.parse_network` </span>
<span class="sd">    edge_MOA : np.array</span>
<span class="sd">        a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the </span>
<span class="sd">        second row is a boolean of whether the interactions are inhibiting</span>
<span class="sd">        output from  `SignalingModel.parse_network`</span>
<span class="sd">    n_network_nodes : int</span>
<span class="sd">        the number of nodes in the network</span>
<span class="sd">    bionet_params : Dict[str, float]</span>
<span class="sd">        training parameters for the model</span>
<span class="sd">        see `SignalingModel.set_training_parameters`</span>
<span class="sd">    activation_function : str, optional</span>
<span class="sd">        RNN activation function, by default &#39;MML&#39;</span>
<span class="sd">        options include:</span>
<span class="sd">            - &#39;MML&#39;: Michaelis-Menten-like</span>
<span class="sd">            - &#39;leaky_relu&#39;: Leaky ReLU</span>
<span class="sd">            - &#39;sigmoid&#39;: sigmoid </span>
<span class="sd">    dtype : torch.dtype, optional</span>
<span class="sd">       datatype to store values in torch, by default torch.float32</span>
<span class="sd">    device : str</span>
<span class="sd">        whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">    seed : int</span>
<span class="sd">        random seed for torch and numpy operations, by default 888</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="o">=</span> <span class="n">bionet_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span> <span class="o">=</span> <span class="n">n_network_nodes</span>
    <span class="c1"># TODO: delete these _in _out?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span> <span class="o">=</span> <span class="n">n_network_nodes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_out</span> <span class="o">=</span> <span class="n">n_network_nodes</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span> <span class="o">=</span> <span class="p">(</span><span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">),</span> 
                      <span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">np_to_torch</span><span class="p">(</span><span class="n">edge_MOA</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># initialize weights and biases</span>
    <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weights</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">weights_MOA</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_mask_MOA</span><span class="p">()</span> <span class="c1"># mechanism of action </span>

    <span class="c1"># activation function</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;activation&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;delta&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">onestepdelta_activation_factor</span> <span class="o">=</span> <span class="n">activation_function_map</span><span class="p">[</span><span class="n">activation_function</span><span class="p">][</span><span class="s1">&#39;onestepdelta&#39;</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.count_sign_mismatch" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">count_sign_mismatch</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Counts total sign mismatches identified in <code>get_sign_mistmatch</code></p>
<h6 id="LEMBAS.model.bionetwork.BioNet.count_sign_mismatch--returns">Returns</h6>
<p>n_sign_mismatches : float
    the total number of sign mismatches at <code>iter</code></p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">count_sign_mismatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Counts total sign mismatches identified in `get_sign_mistmatch`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    n_sign_mismatches : float</span>
<span class="sd">        the total number of sign mismatches at `iter`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sign_mismatches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_sign_mistmatch</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">n_sign_mismatches</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Learn the edeg weights within the signaling network topology.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.forward--parameters">Parameters</h6>
<p>X_full : torch.Tensor
    the linearly scaled ligand inputs. Shape is (samples x network nodes). Output of ProjectInput.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.forward--returns">Returns</h6>
<p>Y_full :  torch.Tensor
    the signaling network scaled by learned interaction weights. Shape is (samples x network nodes).</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learn the edeg weights within the signaling network topology.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_full : torch.Tensor</span>
<span class="sd">        the linearly scaled ligand inputs. Shape is (samples x network nodes). Output of ProjectInput.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Y_full :  torch.Tensor</span>
<span class="sd">        the signaling network scaled by learned interaction weights. Shape is (samples x network nodes).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="c1"># fill non-interacting edges with 0</span>

    <span class="n">X_bias</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="c1"># this is the bias with the projection_amplitude included</span>
    <span class="n">X_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X_bias</span><span class="p">)</span> <span class="c1">#initialize all values at 0</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;max_steps&#39;</span><span class="p">]):</span> <span class="c1"># like an RNN, updating from previous time step</span>
        <span class="n">X_old</span> <span class="o">=</span> <span class="n">X_new</span>
        <span class="n">X_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">X_new</span><span class="p">)</span> <span class="c1"># scale matrix by edge weights</span>
        <span class="n">X_new</span> <span class="o">=</span> <span class="n">X_new</span> <span class="o">+</span> <span class="n">X_bias</span>  <span class="c1"># add original values and bias       </span>
        <span class="n">X_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;leak&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">):</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X_new</span> <span class="o">-</span> <span class="n">X_old</span><span class="p">))</span>    
            <span class="k">if</span> <span class="n">diff</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;tolerance&#39;</span><span class="p">]):</span>
                <span class="k">break</span>

    <span class="n">Y_full</span> <span class="o">=</span> <span class="n">X_new</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">Y_full</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.get_SS_loss" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_SS_loss</span><span class="p">(</span><span class="n">Y_full</span><span class="p">,</span> <span class="n">spectral_loss_factor</span><span class="p">,</span> <span class="n">subset_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p><em>summary</em></p>
<h6 id="LEMBAS.model.bionetwork.BioNet.get_SS_loss--parameters">Parameters</h6>
<p>Y_full : torch.Tensor
    output of the forward pass
    ensure to run <code>torch.Tensor.detach</code> method prior to inputting so that gradient calculations are not effected
spectral_loss_factor : float
    <em>description</em>
subset_n : int, optional
    <em>description</em>, by default 10</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.get_SS_loss--returns">Returns</h6>
<p><em>type</em>
    <em>description</em></p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_SS_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">spectral_loss_factor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">subset_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    Y_full : torch.Tensor</span>
<span class="sd">        output of the forward pass</span>
<span class="sd">        ensure to run `torch.Tensor.detach` method prior to inputting so that gradient calculations are not effected</span>
<span class="sd">    spectral_loss_factor : float</span>
<span class="sd">        _description_</span>
<span class="sd">    subset_n : int, optional</span>
<span class="sd">        _description_, by default 10</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    _type_</span>
<span class="sd">        _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spectral_loss_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">spectral_loss_factor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">exp_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;exp_factor&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span><span class="p">)</span>
    <span class="n">selected_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:</span><span class="n">subset_n</span><span class="p">]</span>

    <span class="n">SS_deviation</span><span class="p">,</span> <span class="n">aprox_spectral_radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_SS_deviation</span><span class="p">(</span><span class="n">Y_full</span><span class="p">[</span><span class="n">selected_values</span><span class="p">,:],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>        
    <span class="n">spectral_radius_factor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">exp_factor</span><span class="o">*</span><span class="p">(</span><span class="n">aprox_spectral_radius</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]))</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">spectral_radius_factor</span> <span class="o">*</span> <span class="n">SS_deviation</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">SS_deviation</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">spectral_loss_factor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">aprox_spectral_radius</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">aprox_spectral_radius</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_ss_seed_counter</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># new seed each time this (and _get_SS_deviation) is called</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">aprox_spectral_radius</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.get_sign_mistmatch" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_sign_mistmatch</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Identifies edge weights in network that have a sign that does not agree
with the known mode of action.</p>
<p>Mode of action: stimulating interactions are expected to have positive weights and inhibiting interactions
are expected to have negative weights.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.get_sign_mistmatch--returns">Returns</h6>
<p>sign_mismatch : torch.Tensor
    a binary adjacency matrix of all nodes in the signaling network, where values are 1 if they do not 
    match the mode of action and 0 if they match the mode of action or have an unknown mode of action</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_sign_mistmatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Identifies edge weights in network that have a sign that does not agree</span>
<span class="sd">    with the known mode of action.</span>

<span class="sd">    Mode of action: stimulating interactions are expected to have positive weights and inhibiting interactions</span>
<span class="sd">    are expected to have negative weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    sign_mismatch : torch.Tensor</span>
<span class="sd">        a binary adjacency matrix of all nodes in the signaling network, where values are 1 if they do not </span>
<span class="sd">        match the mode of action and 0 if they match the mode of action or have an unknown mode of action</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_MOA</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> 
    <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="n">sign_mismatch</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_MOA</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># do not penalize sign mismatches of unknown interactions</span>

    <span class="k">return</span> <span class="n">sign_mismatch</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.initialize_weight_values" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">initialize_weight_values</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Initialize the RNN weight_values for all interactions in the signaling network.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.initialize_weight_values--returns">Returns</h6>
<p>weight_values : torch.Tensor
    a torch.Tensor with randomly initialized values for each signaling network interaction
bias : torch.Tensor
    a torch.Tensor with randomly initialized values for each signaling network node</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_weight_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the RNN weight_values for all interactions in the signaling network.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weight_values : torch.Tensor</span>
<span class="sd">        a torch.Tensor with randomly initialized values for each signaling network interaction</span>
<span class="sd">    bias : torch.Tensor</span>
<span class="sd">        a torch.Tensor with randomly initialized values for each signaling network node</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">network_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># the target nodes receiving an edge</span>
    <span class="n">n_interactions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">network_targets</span><span class="p">)</span>

    <span class="n">set_seeds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">weight_values</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_interactions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">weight_values</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]]</span> <span class="o">=</span> <span class="o">-</span><span class="n">weight_values</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]]</span> <span class="c1"># make those that are inhibiting negative</span>

    <span class="n">bias</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">nt_idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">network_targets</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">weight_values</span><span class="p">[</span><span class="n">network_targets</span> <span class="o">==</span> <span class="n">nt_idx</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">):</span>
            <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">nt_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">weight_values</span><span class="p">,</span> <span class="n">bias</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.initialize_weights" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">initialize_weights</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Initializes weights and masks for interacting nodes and mechanism of action.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.initialize_weights--returns">Returns</h6>
<p>weights : torch.Tensor
    a torch.Tensor adjacency matrix with randomly initialized values for each signaling network interaction
bias : torch.Tensor
    a torch.Tensor with randomly initialized values for each signaling network node</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes weights and masks for interacting nodes and mechanism of action.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights : torch.Tensor</span>
<span class="sd">        a torch.Tensor adjacency matrix with randomly initialized values for each signaling network interaction</span>
<span class="sd">    bias : torch.Tensor</span>
<span class="sd">        a torch.Tensor with randomly initialized values for each signaling network node</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">weight_values</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_weight_values</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_mask</span><span class="p">()</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency matrix</span>
    <span class="n">weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_values</span>

    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.make_mask" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">make_mask</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Generates a mask for adjacency matrix for non-interacting nodes.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.make_mask--returns">Returns</h6>
<p>weights_mask : torch.Tensor
    a boolean adjacency matrix of all nodes in the signaling network, masking (True) interactions that are not present</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">make_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a mask for adjacency matrix for non-interacting nodes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights_mask : torch.Tensor</span>
<span class="sd">        a boolean adjacency matrix of all nodes in the signaling network, masking (True) interactions that are not present</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">weights_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency list format (targets (rows)--&gt; sources (columns))</span>
    <span class="n">weights_mask</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># if interaction is present, do not mask</span>
    <span class="n">weights_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">weights_mask</span><span class="p">)</span> <span class="c1"># make non-interacting edges False and vice-vesa</span>
    <span class="k">return</span> <span class="n">weights_mask</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.make_mask_MOA" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">make_mask_MOA</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Generates mask (and weights) for adjacency matrix for non-interacting nodes AND nodes were mode of action (stimulating/inhibiting) 
is unknown.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.make_mask_MOA--returns">Returns</h6>
<p>weights_MOA : torch.Tensor
    an adjacency matrix of all nodes in the signaling network, with activating interactions set to 1, inhibiting interactions set 
    to -1, and interactions that do not exist or have an unknown mechanism of action (stimulating/inhibiting) set to 0
mask_MOA : torch.Tensor
    a boolean adjacency matrix of all nodes in the signaling network, with interactions that do not exist or have an unknown 
    mechanism of action masked (True)</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">make_mask_MOA</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates mask (and weights) for adjacency matrix for non-interacting nodes AND nodes were mode of action (stimulating/inhibiting) </span>
<span class="sd">    is unknown.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights_MOA : torch.Tensor</span>
<span class="sd">        an adjacency matrix of all nodes in the signaling network, with activating interactions set to 1, inhibiting interactions set </span>
<span class="sd">        to -1, and interactions that do not exist or have an unknown mechanism of action (stimulating/inhibiting) set to 0</span>
<span class="sd">    mask_MOA : torch.Tensor</span>
<span class="sd">        a boolean adjacency matrix of all nodes in the signaling network, with interactions that do not exist or have an unknown </span>
<span class="sd">        mechanism of action masked (True)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">signed_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_MOA</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="c1">#1=activation -1=inhibition, 0=unknown</span>
    <span class="n">weights_MOA</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_network_nodes_in</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># adjacency matrix</span>
    <span class="n">weights_MOA</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">signed_MOA</span>
    <span class="n">mask_MOA</span> <span class="o">=</span> <span class="n">weights_MOA</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">weights_MOA</span><span class="p">,</span> <span class="n">mask_MOA</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.prescale_weights" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">prescale_weights</span><span class="p">(</span><span class="n">target_radius</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Scale weights according to spectral radius</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.prescale_weights--parameters">Parameters</h6>
<p>target_radius : float, optional
    <em>description</em>, by default 0.8</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">prescale_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_radius</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Scale weights according to spectral radius</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target_radius : float, optional</span>
<span class="sd">        _description_, by default 0.8</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">eigen_value</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">eigs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># first eigen value</span>
    <span class="n">spectral_radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">eigen_value</span><span class="p">)</span>

    <span class="n">factor</span> <span class="o">=</span> <span class="n">target_radius</span><span class="o">/</span><span class="n">spectral_radius</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">factor</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.BioNet.sign_regularization" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sign_regularization</span><span class="p">(</span><span class="n">lambda_L1</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L1 regularization term for the neural network parameters that 
do not fit the mechanism of action (i.e., negative weights for stimulating interactions or positive weights for inhibiting interactions).
Only penalizes sign mismatches of known MOA.</p>
<h6 id="LEMBAS.model.bionetwork.BioNet.sign_regularization--parameters">Parameters</h6>
<p>lambda_L1 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.BioNet.sign_regularization--returns">Returns</h6>
<p>loss : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sign_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L1</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L1 regularization term for the neural network parameters that </span>
<span class="sd">    do not fit the mechanism of action (i.e., negative weights for stimulating interactions or positive weights for inhibiting interactions).</span>
<span class="sd">    Only penalizes sign mismatches of known MOA.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_L1 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lambda_L1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_L1</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">sign_mismatch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sign_mistmatch</span><span class="p">()</span> <span class="c1"># will not penalize sign mismatches of unknown interactions</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">sign_mismatch</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h4 id="LEMBAS.model.bionetwork.ProjectInput" class="doc doc-heading">
          <code>ProjectInput</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.Module">Module</span></code></p>

  
      <p>Generate all nodes for the signaling network and linearly scale input ligand values by NN parameters.</p>

            <details class="quote">
              <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ProjectInput</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate all nodes for the signaling network and linearly scale input ligand values by NN parameters.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_idx_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">input_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">projection_amplitude</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        node_idx_map : Dict[str, int]</span>
<span class="sd">            a dictionary mapping node labels (str) to the node index (float)</span>
<span class="sd">            generated by `SignalingModel.parse_network`</span>
<span class="sd">        input_labels : np.array</span>
<span class="sd">            names of the input nodes (ligands) from net</span>
<span class="sd">        projection_amplitude : Union[int, float]</span>
<span class="sd">            value with which to initialize learned linear scaling parameters, by default 1. (if turn require_grad = False for this layer, this is still applied simply as a constant linear scalar in each forward pass)</span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">            datatype to store values in torch, by default torch.float32</span>
<span class="sd">        device : str</span>
<span class="sd">            whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">)</span> <span class="c1"># number of nodes total in prior knowledge network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_node_order</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">node_idx_map</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_labels</span><span class="p">],</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># idx representation of ligand inputs</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># scaled input weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Learn the weights for the input ligands to the signaling network (if grad_fn set to False, </span>
<span class="sd">        simply scales by projection amplitude).</span>
<span class="sd">        Transform from ligand input (samples x ligands) to full signaling network (samples x network nodes).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_in : torch.Tensor</span>
<span class="sd">            the ligand concentration inputs. Shape is (samples x ligands). </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_full :  torch.Tensor</span>
<span class="sd">            the linearly scaled ligand inputs. Shape is (samples x network nodes)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># shape of (samples x total nodes in network)</span>
        <span class="n">X_full</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_node_order</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">X_in</span> <span class="c1"># only modify those nodes that are part of the input (ligands)</span>
        <span class="k">return</span> <span class="n">X_full</span>

    <span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>
<span class="sd">        Here, this pushes learned parameters towards `projection_amplitude` </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        projection_L2 : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if removed the `- self.projection_amplitude` part, would force weights to 0, thus shrinking ligand inputs</span>
        <span class="n">projection_L2</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span><span class="p">))</span>  
        <span class="k">return</span> <span class="n">projection_L2</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectInput.L2_reg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for the neural network parameters.
Here, this pushes learned parameters towards <code>projection_amplitude</code> </p>
<h6 id="LEMBAS.model.bionetwork.ProjectInput.L2_reg--parameters">Parameters</h6>
<p>lambda_2 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.ProjectInput.L2_reg--returns">Returns</h6>
<p>projection_L2 : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>
<span class="sd">    Here, this pushes learned parameters towards `projection_amplitude` </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    projection_L2 : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># if removed the `- self.projection_amplitude` part, would force weights to 0, thus shrinking ligand inputs</span>
    <span class="n">projection_L2</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span><span class="p">))</span>  
    <span class="k">return</span> <span class="n">projection_L2</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectInput.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">projection_amplitude</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Initialization method.</p>
<h6 id="LEMBAS.model.bionetwork.ProjectInput.__init__--parameters">Parameters</h6>
<p>node_idx_map : Dict[str, int]
    a dictionary mapping node labels (str) to the node index (float)
    generated by <code>SignalingModel.parse_network</code>
input_labels : np.array
    names of the input nodes (ligands) from net
projection_amplitude : Union[int, float]
    value with which to initialize learned linear scaling parameters, by default 1. (if turn require_grad = False for this layer, this is still applied simply as a constant linear scalar in each forward pass)
dtype : torch.dtype, optional
    datatype to store values in torch, by default torch.float32
device : str
    whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_idx_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">input_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">projection_amplitude</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node_idx_map : Dict[str, int]</span>
<span class="sd">        a dictionary mapping node labels (str) to the node index (float)</span>
<span class="sd">        generated by `SignalingModel.parse_network`</span>
<span class="sd">    input_labels : np.array</span>
<span class="sd">        names of the input nodes (ligands) from net</span>
<span class="sd">    projection_amplitude : Union[int, float]</span>
<span class="sd">        value with which to initialize learned linear scaling parameters, by default 1. (if turn require_grad = False for this layer, this is still applied simply as a constant linear scalar in each forward pass)</span>
<span class="sd">    dtype : torch.dtype, optional</span>
<span class="sd">        datatype to store values in torch, by default torch.float32</span>
<span class="sd">    device : str</span>
<span class="sd">        whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">)</span> <span class="c1"># number of nodes total in prior knowledge network</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_node_order</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">node_idx_map</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_labels</span><span class="p">],</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># idx representation of ligand inputs</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># scaled input weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectInput.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X_in</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Learn the weights for the input ligands to the signaling network (if grad_fn set to False, 
simply scales by projection amplitude).
Transform from ligand input (samples x ligands) to full signaling network (samples x network nodes).</p>
<h6 id="LEMBAS.model.bionetwork.ProjectInput.forward--parameters">Parameters</h6>
<p>X_in : torch.Tensor
    the ligand concentration inputs. Shape is (samples x ligands). </p>
<h6 id="LEMBAS.model.bionetwork.ProjectInput.forward--returns">Returns</h6>
<p>X_full :  torch.Tensor
    the linearly scaled ligand inputs. Shape is (samples x network nodes)</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learn the weights for the input ligands to the signaling network (if grad_fn set to False, </span>
<span class="sd">    simply scales by projection amplitude).</span>
<span class="sd">    Transform from ligand input (samples x ligands) to full signaling network (samples x network nodes).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_in : torch.Tensor</span>
<span class="sd">        the ligand concentration inputs. Shape is (samples x ligands). </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X_full :  torch.Tensor</span>
<span class="sd">        the linearly scaled ligand inputs. Shape is (samples x network nodes)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># shape of (samples x total nodes in network)</span>
    <span class="n">X_full</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_node_order</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">X_in</span> <span class="c1"># only modify those nodes that are part of the input (ligands)</span>
    <span class="k">return</span> <span class="n">X_full</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h4 id="LEMBAS.model.bionetwork.ProjectOutput" class="doc doc-heading">
          <code>ProjectOutput</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.Module">Module</span></code></p>

  
      <p>Transforms signaling network to TF activity.</p>

            <details class="quote">
              <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ProjectOutput</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms signaling network to TF activity.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_idx_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">output_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
                    <span class="n">projection_amplitude</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        node_idx_map : Dict[str, int]</span>
<span class="sd">            a dictionary mapping node labels (str) to the node index (float)</span>
<span class="sd">            generated by `SignalingModel.parse_network`</span>
<span class="sd">        output_labels : np.array</span>
<span class="sd">           names of the out nodes (TFs) from net</span>
<span class="sd">        projection_amplitude : Union[int, float], optional</span>
<span class="sd">            value with which to initialize learned linear scaling parameters, by default 1. </span>
<span class="sd">            (if turn require_grad = False for this layer, this is still applied  simply </span>
<span class="sd">            as a constant linear scalar in each forward pass)</span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">            datatype to store values in torch, by default torch.float32</span>
<span class="sd">        device : str, optional</span>
<span class="sd">            whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">size_in</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_node_order</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">node_idx_map</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_labels</span><span class="p">],</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span> <span class="c1"># idx representation of TF outputs</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Learn the weights for the output TFs of the signaling network (if grad_fn set to False, </span>
<span class="sd">        simply scales by projection amplitude).</span>
<span class="sd">        Transforms full signaling network  (samples x network nodes) to only the space of the TFs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Y_full : torch.Tensor</span>
<span class="sd">            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). </span>
<span class="sd">            Output of BioNet.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Y_hat :  torch.Tensor</span>
<span class="sd">            the linearly scaled TF outputs. Shape is (samples x TFs)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">Y_full</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_node_order</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">Y_hat</span>

    <span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>
<span class="sd">        Here, this pushes learned parameters towards `projection_amplitude` </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        projection_L2 : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">projection_L2</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span><span class="p">))</span>  
        <span class="k">return</span> <span class="n">projection_L2</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectOutput.L2_reg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for the neural network parameters.
Here, this pushes learned parameters towards <code>projection_amplitude</code> </p>
<h6 id="LEMBAS.model.bionetwork.ProjectOutput.L2_reg--parameters">Parameters</h6>
<p>lambda_2 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.ProjectOutput.L2_reg--returns">Returns</h6>
<p>projection_L2 : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>
<span class="sd">    Here, this pushes learned parameters towards `projection_amplitude` </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_2 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    projection_L2 : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">projection_L2</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span><span class="p">))</span>  
    <span class="k">return</span> <span class="n">projection_L2</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectOutput.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">,</span> <span class="n">output_labels</span><span class="p">,</span> <span class="n">projection_amplitude</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Initialization method.</p>
<h6 id="LEMBAS.model.bionetwork.ProjectOutput.__init__--parameters">Parameters</h6>
<p>node_idx_map : Dict[str, int]
    a dictionary mapping node labels (str) to the node index (float)
    generated by <code>SignalingModel.parse_network</code>
output_labels : np.array
   names of the out nodes (TFs) from net
projection_amplitude : Union[int, float], optional
    value with which to initialize learned linear scaling parameters, by default 1. 
    (if turn require_grad = False for this layer, this is still applied  simply 
    as a constant linear scalar in each forward pass)
dtype : torch.dtype, optional
    datatype to store values in torch, by default torch.float32
device : str, optional
    whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_idx_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">output_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
                <span class="n">projection_amplitude</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialization method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node_idx_map : Dict[str, int]</span>
<span class="sd">        a dictionary mapping node labels (str) to the node index (float)</span>
<span class="sd">        generated by `SignalingModel.parse_network`</span>
<span class="sd">    output_labels : np.array</span>
<span class="sd">       names of the out nodes (TFs) from net</span>
<span class="sd">    projection_amplitude : Union[int, float], optional</span>
<span class="sd">        value with which to initialize learned linear scaling parameters, by default 1. </span>
<span class="sd">        (if turn require_grad = False for this layer, this is still applied  simply </span>
<span class="sd">        as a constant linear scalar in each forward pass)</span>
<span class="sd">    dtype : torch.dtype, optional</span>
<span class="sd">        datatype to store values in torch, by default torch.float32</span>
<span class="sd">    device : str, optional</span>
<span class="sd">        whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">size_in</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_idx_map</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_labels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">output_node_order</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">node_idx_map</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_labels</span><span class="p">],</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span> <span class="c1"># idx representation of TF outputs</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.ProjectOutput.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">Y_full</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Learn the weights for the output TFs of the signaling network (if grad_fn set to False, 
simply scales by projection amplitude).
Transforms full signaling network  (samples x network nodes) to only the space of the TFs.</p>
<h6 id="LEMBAS.model.bionetwork.ProjectOutput.forward--parameters">Parameters</h6>
<p>Y_full : torch.Tensor
    the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). 
    Output of BioNet.</p>
<h6 id="LEMBAS.model.bionetwork.ProjectOutput.forward--returns">Returns</h6>
<p>Y_hat :  torch.Tensor
    the linearly scaled TF outputs. Shape is (samples x TFs)</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learn the weights for the output TFs of the signaling network (if grad_fn set to False, </span>
<span class="sd">    simply scales by projection amplitude).</span>
<span class="sd">    Transforms full signaling network  (samples x network nodes) to only the space of the TFs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    Y_full : torch.Tensor</span>
<span class="sd">        the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). </span>
<span class="sd">        Output of BioNet.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Y_hat :  torch.Tensor</span>
<span class="sd">        the linearly scaled TF outputs. Shape is (samples x TFs)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">Y_full</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_node_order</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Y_hat</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>

<div class="doc doc-object doc-class">



<h4 id="LEMBAS.model.bionetwork.SignalingModel" class="doc doc-heading">
          <code>SignalingModel</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.nn.Module">Module</span></code></p>

  
      <p>Constructs the signaling network based RNN.</p>

            <details class="quote">
              <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SignalingModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructs the signaling network based RNN.&quot;&quot;&quot;</span>
    <span class="n">DEFAULT_TRAINING_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;target_steps&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span> <span class="s1">&#39;exp_factor&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;leak&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;tolerance&#39;</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">X_in</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_out</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
                 <span class="n">projection_amplitude_in</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection_amplitude_out</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">ban_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> 
                 <span class="n">source_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> 
                <span class="n">bionet_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                 <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">&#39;MML&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">888</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parse the signaling network and build the model layers.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        net: pd.DataFrame</span>
<span class="sd">            signaling network adjacency list with the following columns:</span>
<span class="sd">                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1). Exclude non-interacting (0) nodes. </span>
<span class="sd">                - `source_label`: source node column name</span>
<span class="sd">                - `target_label`: target node column name</span>
<span class="sd">        X_in : pd.DataFrame</span>
<span class="sd">            input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). </span>
<span class="sd">        y_out : pd.DataFrame</span>
<span class="sd">            output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF. </span>
<span class="sd">        ban_list : List[str], optional</span>
<span class="sd">            a list of signaling network nodes to disregard, by default None</span>
<span class="sd">        projection_amplitude_in : Union[int, float]</span>
<span class="sd">            value with which to scale ligand inputs by, by default 1 (see `ProjectInput` for details, can also be tuned as a learned parameter in the model)</span>
<span class="sd">        projection_amplitude_out : float</span>
<span class="sd">             value with which to scale TF activity outputs by, by default 1 (see `ProjectOutput` for details, can also be tuned as a learned parameter in the model)</span>
<span class="sd">        bionet_params : Dict[str, float], optional</span>
<span class="sd">            training parameters for the model, by default None</span>
<span class="sd">            Key values include:</span>
<span class="sd">                - &#39;max_steps&#39;: maximum number of time steps of the RNN, by default 300</span>
<span class="sd">                - &#39;tolerance&#39;: threshold at which to break RNN; based on magnitude of change of updated edge weight values, by default 1e-5</span>
<span class="sd">                - &#39;leak&#39;: parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>
<span class="sd">                - &#39;spectral_target&#39;: _description_, by default np.exp(np.log(params[&#39;tolerance&#39;])/params[&#39;target_steps&#39;])</span>
<span class="sd">                - &#39;exp_factor&#39;: _description_, by default 20</span>
<span class="sd">        activation_function : str, optional</span>
<span class="sd">            RNN activation function, by default &#39;MML&#39;</span>
<span class="sd">            options include:</span>
<span class="sd">                - &#39;MML&#39;: Michaelis-Menten-like</span>
<span class="sd">                - &#39;leaky_relu&#39;: Leaky ReLU</span>
<span class="sd">                - &#39;sigmoid&#39;: sigmoid </span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">            datatype to store values in torch, by default torch.float32</span>
<span class="sd">        device : str</span>
<span class="sd">            whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">        seed : int</span>
<span class="sd">            random seed for torch and numpy operations, by default 888</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span> <span class="o">=</span> <span class="n">projection_amplitude_out</span>

        <span class="n">edge_list</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">,</span> <span class="n">edge_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">ban_list</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">,</span> <span class="n">source_label</span><span class="p">,</span> <span class="n">target_label</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">bionet_params</span><span class="p">:</span>
            <span class="n">bionet_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_TRAINING_PARAMETERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bionet_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_training_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">bionet_params</span><span class="p">)</span>

        <span class="c1"># filter for nodes in the network, sorting by node_labels order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span> <span class="o">=</span> <span class="n">X_in</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">X_in</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span> <span class="o">=</span> <span class="n">y_out</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">y_out</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">)]</span>

        <span class="c1"># define model layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">ProjectInput</span><span class="p">(</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">,</span> 
                                        <span class="n">input_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> 
                                        <span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude_in</span><span class="p">,</span> 
                                        <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> 
                                        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span> <span class="o">=</span> <span class="n">BioNet</span><span class="p">(</span><span class="n">edge_list</span> <span class="o">=</span> <span class="n">edge_list</span><span class="p">,</span> 
                                        <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">edge_MOA</span><span class="p">,</span> 
                                        <span class="n">n_network_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_labels</span><span class="p">),</span> 
                                        <span class="n">bionet_params</span> <span class="o">=</span> <span class="n">bionet_params</span><span class="p">,</span> 
                                        <span class="n">activation_function</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">,</span> 
                                        <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">ProjectOutput</span><span class="p">(</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">,</span> 
                                          <span class="n">output_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> 
                                          <span class="n">projection_amplitude</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span><span class="p">,</span> 
                                          <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">ban_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">weight_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> <span class="n">source_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parse adjacency network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        net: pd.DataFrame</span>
<span class="sd">            signaling network adjacency list with the following columns:</span>
<span class="sd">                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0). Exclude non-interacting (0)</span>
<span class="sd">                nodes. </span>
<span class="sd">                - `source_label`: source node column name</span>
<span class="sd">                - `target_label`: target node column name</span>
<span class="sd">        ban_list : List[str], optional</span>
<span class="sd">            a list of signaling network nodes to disregard, by default None</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        edge_list : np.array</span>
<span class="sd">            a (2, net.shape[0]) array where the first row represents the indices for the target node and the </span>
<span class="sd">            second row represents the indices for the source node. net.shape[0] is the total # of interactions</span>
<span class="sd">        node_labels : list</span>
<span class="sd">            a list of the network nodes in the same order as the indices</span>
<span class="sd">        edge_MOA : np.array</span>
<span class="sd">            a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the </span>
<span class="sd">            second row is a boolean of whether the interactions are inhibiting. </span>

<span class="sd">            Note: Edge_list includes interactions that are not delineated as activating OR inhibiting, s.t. edge_MOA records this </span>
<span class="sd">            as [False, False].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ban_list</span><span class="p">:</span>
            <span class="n">ban_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">!=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">weight_label</span> <span class="o">+</span> <span class="s1">&#39; values must be 1 or -1&#39;</span><span class="p">)</span>

        <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="o">~</span> <span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">ban_list</span><span class="p">)]</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="o">~</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">ban_list</span><span class="p">)]</span>

        <span class="c1"># create an edge list with node incides</span>
        <span class="n">node_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]])</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">node_name</span> <span class="k">for</span> <span class="n">node_name</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_labels</span><span class="p">)}</span>

        <span class="n">source_indices</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">target_indices</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># # get edge list</span>
        <span class="c1"># edge_list = np.array((target_indices, source_indices))</span>
        <span class="c1"># edge_MOA = net[weight_label].values</span>
        <span class="c1"># get edge list *ordered by source-target node index*</span>
        <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_labels</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="n">source_indices</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span> <span class="c1"># calculate adjacency matrix</span>
        <span class="n">source_indices</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">,</span> <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="c1"># re-orders adjacency list by index</span>
        <span class="n">edge_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">target_indices</span><span class="p">,</span> <span class="n">source_indices</span><span class="p">))</span> 
        <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">edge_MOA</span><span class="o">==</span><span class="mi">1</span><span class="p">],[</span><span class="n">edge_MOA</span><span class="o">==-</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># convert to boolean</span>

        <span class="k">return</span> <span class="n">edge_list</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">,</span> <span class="n">edge_MOA</span>

    <span class="k">def</span> <span class="nf">df_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a pandas dataframe to the appropriate torch.tensor&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_training_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">attributes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the parameters for training the model. Overrides default parameters with attributes if specified.</span>
<span class="sd">        Adapted from LEMBAS `trainingParameters`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        attributes : dict</span>
<span class="sd">            keys are parameter names and values are parameter value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#set defaults</span>
        <span class="n">default_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_TRAINING_PARAMETERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">allowed_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">default_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">attributes</span><span class="p">}</span>
        <span class="k">if</span> <span class="s1">&#39;spectral_target&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">params</span><span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;tolerance&#39;</span><span class="p">])</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;target_steps&#39;</span><span class="p">])</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">allowed_params</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">params</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_in</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Linearly scales ligand inputs, learns weights for signaling network interactions, and transforms this to TF activity. See</span>
<span class="sd">        `forward` methods of each layer for details.&quot;&quot;&quot;</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">X_in</span><span class="p">)</span> <span class="c1"># input ligands to signaling network</span>
        <span class="n">Y_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span> <span class="c1"># RNN of full signaling network</span>
        <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">Y_full</span><span class="p">)</span> <span class="c1"># TF outputs of signaling network</span>
        <span class="k">return</span> <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y_full</span>

    <span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_L2 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">         : torch.Tensor</span>
<span class="sd">            the regularization term (as the sum of the regularization terms for each layer)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ligand_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the ligand biases. Intuitively, extracellular ligands should not contribute to </span>
<span class="sd">        &quot;baseline (i.e., unstimulated) activity&quot; affecting intrecllular signaling nodes and thus TF outputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_L2 : Annotated[float, Ge(0)]</span>
<span class="sd">            the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">bias</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">input_node_order</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">uniform_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
                     <span class="n">target_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">target_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for deviations of the nodes in Y_full from that of a uniform distribution between </span>
<span class="sd">        `target_min` and `target_max`. </span>
<span class="sd">        Note, this penalizes both deviations from the uniform distribution AND values that are out of range (like a double penalty).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lambda_L2 : float</span>
<span class="sd">            scaling factor for state loss</span>
<span class="sd">        Y_full : torch.Tensor</span>
<span class="sd">            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). </span>
<span class="sd">            Output of BioNet.</span>
<span class="sd">        target_min : float, optional</span>
<span class="sd">            minimum values for nodes in Y_full to take on, by default 0.0</span>
<span class="sd">        target_max : float, optional</span>
<span class="sd">            maximum values for nodes in Y_full to take on, by default 1/`self.projection_amplitude_out`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss : torch.Tensor</span>
<span class="sd">            the regularization term</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lambda_L2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># loss = lambda_L2 * expected_uniform_distribution(Y_full, target_max = 1/self.projectionAmplitude)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">target_max</span><span class="p">:</span>
            <span class="n">target_max</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span>

        <span class="n">sorted_Y_full</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">Y_full</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># sorts each column (signaling network node) in ascending order</span>
        <span class="n">target_distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">target_min</span><span class="p">,</span> <span class="n">target_max</span><span class="p">,</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">dist_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">sorted_Y_full</span> <span class="o">-</span> <span class="n">target_distribution</span><span class="p">))</span> <span class="c1"># difference in distribution</span>
        <span class="n">below_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">target_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">Y_full</span><span class="o">-</span><span class="n">target_min</span><span class="p">))</span> <span class="c1"># those that are below the minimum value</span>
        <span class="n">above_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">target_max</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">Y_full</span><span class="o">-</span><span class="n">target_max</span><span class="p">))</span> <span class="c1"># those that are above the maximum value</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L2</span><span class="o">*</span><span class="p">(</span><span class="n">dist_loss</span> <span class="o">+</span> <span class="n">below_loss</span> <span class="o">+</span> <span class="n">above_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">add_gradient_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds noise to backwards pass gradient calculations. Use during training to make model more robust. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        noise_level : Union[float, int]</span>
<span class="sd">            scaling factor for amount of noise to add </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">all_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
            <span class="n">set_seeds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_params</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">all_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="o">+=</span> <span class="p">(</span><span class="n">noise_level</span> <span class="o">*</span> <span class="n">all_noise</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># new random noise each time function is called</span>

    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.L2_reg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for the neural network parameters.</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.L2_reg--parameters">Parameters</h6>
<p>lambda_L2 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.L2_reg--returns">Returns</h6>
<p>: torch.Tensor
    the regularization term (as the sum of the regularization terms for each layer)</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">L2_reg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the neural network parameters.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_L2 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">     : torch.Tensor</span>
<span class="sd">        the regularization term (as the sum of the regularization terms for each layer)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">X_in</span><span class="p">,</span> <span class="n">y_out</span><span class="p">,</span> <span class="n">projection_amplitude_in</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">projection_amplitude_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ban_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight_label</span><span class="o">=</span><span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> <span class="n">source_label</span><span class="o">=</span><span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">bionet_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="s1">&#39;MML&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Parse the signaling network and build the model layers.</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.__init__--parameters">Parameters</h6>
<p>net: pd.DataFrame
    signaling network adjacency list with the following columns:
        - <code>weight_label</code>: whether the interaction is stimulating (1) or inhibiting (-1). Exclude non-interacting (0) nodes. 
        - <code>source_label</code>: source node column name
        - <code>target_label</code>: target node column name
X_in : pd.DataFrame
    input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). 
y_out : pd.DataFrame
    output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF. 
ban_list : List[str], optional
    a list of signaling network nodes to disregard, by default None
projection_amplitude_in : Union[int, float]
    value with which to scale ligand inputs by, by default 1 (see <code>ProjectInput</code> for details, can also be tuned as a learned parameter in the model)
projection_amplitude_out : float
     value with which to scale TF activity outputs by, by default 1 (see <code>ProjectOutput</code> for details, can also be tuned as a learned parameter in the model)
bionet_params : Dict[str, float], optional
    training parameters for the model, by default None
    Key values include:
        - 'max_steps': maximum number of time steps of the RNN, by default 300
        - 'tolerance': threshold at which to break RNN; based on magnitude of change of updated edge weight values, by default 1e-5
        - 'leak': parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01
        - 'spectral_target': <em>description</em>, by default np.exp(np.log(params['tolerance'])/params['target_steps'])
        - 'exp_factor': <em>description</em>, by default 20
activation_function : str, optional
    RNN activation function, by default 'MML'
    options include:
        - 'MML': Michaelis-Menten-like
        - 'leaky_relu': Leaky ReLU
        - 'sigmoid': sigmoid 
dtype : torch.dtype, optional
    datatype to store values in torch, by default torch.float32
device : str
    whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
seed : int
    random seed for torch and numpy operations, by default 888</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">X_in</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_out</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
             <span class="n">projection_amplitude_in</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection_amplitude_out</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
             <span class="n">ban_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> 
             <span class="n">source_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> 
            <span class="n">bionet_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
             <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">&#39;MML&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">888</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse the signaling network and build the model layers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    net: pd.DataFrame</span>
<span class="sd">        signaling network adjacency list with the following columns:</span>
<span class="sd">            - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1). Exclude non-interacting (0) nodes. </span>
<span class="sd">            - `source_label`: source node column name</span>
<span class="sd">            - `target_label`: target node column name</span>
<span class="sd">    X_in : pd.DataFrame</span>
<span class="sd">        input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). </span>
<span class="sd">    y_out : pd.DataFrame</span>
<span class="sd">        output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF. </span>
<span class="sd">    ban_list : List[str], optional</span>
<span class="sd">        a list of signaling network nodes to disregard, by default None</span>
<span class="sd">    projection_amplitude_in : Union[int, float]</span>
<span class="sd">        value with which to scale ligand inputs by, by default 1 (see `ProjectInput` for details, can also be tuned as a learned parameter in the model)</span>
<span class="sd">    projection_amplitude_out : float</span>
<span class="sd">         value with which to scale TF activity outputs by, by default 1 (see `ProjectOutput` for details, can also be tuned as a learned parameter in the model)</span>
<span class="sd">    bionet_params : Dict[str, float], optional</span>
<span class="sd">        training parameters for the model, by default None</span>
<span class="sd">        Key values include:</span>
<span class="sd">            - &#39;max_steps&#39;: maximum number of time steps of the RNN, by default 300</span>
<span class="sd">            - &#39;tolerance&#39;: threshold at which to break RNN; based on magnitude of change of updated edge weight values, by default 1e-5</span>
<span class="sd">            - &#39;leak&#39;: parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01</span>
<span class="sd">            - &#39;spectral_target&#39;: _description_, by default np.exp(np.log(params[&#39;tolerance&#39;])/params[&#39;target_steps&#39;])</span>
<span class="sd">            - &#39;exp_factor&#39;: _description_, by default 20</span>
<span class="sd">    activation_function : str, optional</span>
<span class="sd">        RNN activation function, by default &#39;MML&#39;</span>
<span class="sd">        options include:</span>
<span class="sd">            - &#39;MML&#39;: Michaelis-Menten-like</span>
<span class="sd">            - &#39;leaky_relu&#39;: Leaky ReLU</span>
<span class="sd">            - &#39;sigmoid&#39;: sigmoid </span>
<span class="sd">    dtype : torch.dtype, optional</span>
<span class="sd">        datatype to store values in torch, by default torch.float32</span>
<span class="sd">    device : str</span>
<span class="sd">        whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">    seed : int</span>
<span class="sd">        random seed for torch and numpy operations, by default 888</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span> <span class="o">=</span> <span class="n">projection_amplitude_out</span>

    <span class="n">edge_list</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">,</span> <span class="n">edge_MOA</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">ban_list</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">,</span> <span class="n">source_label</span><span class="p">,</span> <span class="n">target_label</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">bionet_params</span><span class="p">:</span>
        <span class="n">bionet_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_TRAINING_PARAMETERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">bionet_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_training_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">bionet_params</span><span class="p">)</span>

    <span class="c1"># filter for nodes in the network, sorting by node_labels order</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span> <span class="o">=</span> <span class="n">X_in</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">X_in</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span> <span class="o">=</span> <span class="n">y_out</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">y_out</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">)]</span>

    <span class="c1"># define model layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">ProjectInput</span><span class="p">(</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">,</span> 
                                    <span class="n">input_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> 
                                    <span class="n">projection_amplitude</span> <span class="o">=</span> <span class="n">projection_amplitude_in</span><span class="p">,</span> 
                                    <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> 
                                    <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span> <span class="o">=</span> <span class="n">BioNet</span><span class="p">(</span><span class="n">edge_list</span> <span class="o">=</span> <span class="n">edge_list</span><span class="p">,</span> 
                                    <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">edge_MOA</span><span class="p">,</span> 
                                    <span class="n">n_network_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_labels</span><span class="p">),</span> 
                                    <span class="n">bionet_params</span> <span class="o">=</span> <span class="n">bionet_params</span><span class="p">,</span> 
                                    <span class="n">activation_function</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">,</span> 
                                    <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">ProjectOutput</span><span class="p">(</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">,</span> 
                                      <span class="n">output_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> 
                                      <span class="n">projection_amplitude</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span><span class="p">,</span> 
                                      <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.add_gradient_noise" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">add_gradient_noise</span><span class="p">(</span><span class="n">noise_level</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Adds noise to backwards pass gradient calculations. Use during training to make model more robust. </p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.add_gradient_noise--parameters">Parameters</h6>
<p>noise_level : Union[float, int]
    scaling factor for amount of noise to add</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_gradient_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds noise to backwards pass gradient calculations. Use during training to make model more robust. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    noise_level : Union[float, int]</span>
<span class="sd">        scaling factor for amount of noise to add </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
        <span class="n">set_seeds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_params</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
            <span class="n">all_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">all_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="o">+=</span> <span class="p">(</span><span class="n">noise_level</span> <span class="o">*</span> <span class="n">all_noise</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_seed_counter</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># new random noise each time function is called</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.df_to_tensor" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">df_to_tensor</span><span class="p">(</span><span class="n">df</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Converts a pandas dataframe to the appropriate torch.tensor</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">df_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts a pandas dataframe to the appropriate torch.tensor&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">X_in</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Linearly scales ligand inputs, learns weights for signaling network interactions, and transforms this to TF activity. See
<code>forward</code> methods of each layer for details.</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_in</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Linearly scales ligand inputs, learns weights for signaling network interactions, and transforms this to TF activity. See</span>
<span class="sd">    `forward` methods of each layer for details.&quot;&quot;&quot;</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">X_in</span><span class="p">)</span> <span class="c1"># input ligands to signaling network</span>
    <span class="n">Y_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span> <span class="c1"># RNN of full signaling network</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">Y_full</span><span class="p">)</span> <span class="c1"># TF outputs of signaling network</span>
    <span class="k">return</span> <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y_full</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.ligand_regularization" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">ligand_regularization</span><span class="p">(</span><span class="n">lambda_L2</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for the ligand biases. Intuitively, extracellular ligands should not contribute to 
"baseline (i.e., unstimulated) activity" affecting intrecllular signaling nodes and thus TF outputs.</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.ligand_regularization--parameters">Parameters</h6>
<p>lambda_L2 : Annotated[float, Ge(0)]
    the regularization parameter, by default 0 (no penalty) </p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.ligand_regularization--returns">Returns</h6>
<p>loss : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">ligand_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for the ligand biases. Intuitively, extracellular ligands should not contribute to </span>
<span class="sd">    &quot;baseline (i.e., unstimulated) activity&quot; affecting intrecllular signaling nodes and thus TF outputs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_L2 : Annotated[float, Ge(0)]</span>
<span class="sd">        the regularization parameter, by default 0 (no penalty) </span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">bias</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">input_node_order</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.parse_network" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">parse_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">ban_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight_label</span><span class="o">=</span><span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> <span class="n">source_label</span><span class="o">=</span><span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Parse adjacency network.</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.parse_network--parameters">Parameters</h6>
<p>net: pd.DataFrame
    signaling network adjacency list with the following columns:
        - <code>weight_label</code>: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0). Exclude non-interacting (0)
        nodes. 
        - <code>source_label</code>: source node column name
        - <code>target_label</code>: target node column name
ban_list : List[str], optional
    a list of signaling network nodes to disregard, by default None</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.parse_network--returns">Returns</h6>
<p>edge_list : np.array
    a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
    second row represents the indices for the source node. net.shape[0] is the total # of interactions
node_labels : list
    a list of the network nodes in the same order as the indices
edge_MOA : np.array
    a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
    second row is a boolean of whether the interactions are inhibiting. </p>
<div class="highlight"><pre><span></span><code>Note: Edge_list includes interactions that are not delineated as activating OR inhibiting, s.t. edge_MOA records this 
as [False, False].
</code></pre></div>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">parse_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">ban_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
             <span class="n">weight_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> <span class="n">source_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="n">target_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse adjacency network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    net: pd.DataFrame</span>
<span class="sd">        signaling network adjacency list with the following columns:</span>
<span class="sd">            - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0). Exclude non-interacting (0)</span>
<span class="sd">            nodes. </span>
<span class="sd">            - `source_label`: source node column name</span>
<span class="sd">            - `target_label`: target node column name</span>
<span class="sd">    ban_list : List[str], optional</span>
<span class="sd">        a list of signaling network nodes to disregard, by default None</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    edge_list : np.array</span>
<span class="sd">        a (2, net.shape[0]) array where the first row represents the indices for the target node and the </span>
<span class="sd">        second row represents the indices for the source node. net.shape[0] is the total # of interactions</span>
<span class="sd">    node_labels : list</span>
<span class="sd">        a list of the network nodes in the same order as the indices</span>
<span class="sd">    edge_MOA : np.array</span>
<span class="sd">        a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the </span>
<span class="sd">        second row is a boolean of whether the interactions are inhibiting. </span>

<span class="sd">        Note: Edge_list includes interactions that are not delineated as activating OR inhibiting, s.t. edge_MOA records this </span>
<span class="sd">        as [False, False].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ban_list</span><span class="p">:</span>
        <span class="n">ban_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">!=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">weight_label</span> <span class="o">+</span> <span class="s1">&#39; values must be 1 or -1&#39;</span><span class="p">)</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="o">~</span> <span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">ban_list</span><span class="p">)]</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="o">~</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">ban_list</span><span class="p">)]</span>

    <span class="c1"># create an edge list with node incides</span>
    <span class="n">node_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]])</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">node_name</span> <span class="k">for</span> <span class="n">node_name</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_labels</span><span class="p">)}</span>

    <span class="n">source_indices</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="n">source_label</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="n">target_indices</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="n">target_label</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_idx_map</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># # get edge list</span>
    <span class="c1"># edge_list = np.array((target_indices, source_indices))</span>
    <span class="c1"># edge_MOA = net[weight_label].values</span>
    <span class="c1"># get edge list *ordered by source-target node index*</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_labels</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="n">source_indices</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span> <span class="c1"># calculate adjacency matrix</span>
    <span class="n">source_indices</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">,</span> <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="c1"># re-orders adjacency list by index</span>
    <span class="n">edge_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">target_indices</span><span class="p">,</span> <span class="n">source_indices</span><span class="p">))</span> 
    <span class="n">edge_MOA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">edge_MOA</span><span class="o">==</span><span class="mi">1</span><span class="p">],[</span><span class="n">edge_MOA</span><span class="o">==-</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># convert to boolean</span>

    <span class="k">return</span> <span class="n">edge_list</span><span class="p">,</span> <span class="n">node_labels</span><span class="p">,</span> <span class="n">edge_MOA</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.set_training_parameters" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_training_parameters</span><span class="p">(</span><span class="o">**</span><span class="n">attributes</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Set the parameters for training the model. Overrides default parameters with attributes if specified.
Adapted from LEMBAS <code>trainingParameters</code></p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.set_training_parameters--parameters">Parameters</h6>
<p>attributes : dict
    keys are parameter names and values are parameter value</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_training_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">attributes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set the parameters for training the model. Overrides default parameters with attributes if specified.</span>
<span class="sd">    Adapted from LEMBAS `trainingParameters`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    attributes : dict</span>
<span class="sd">        keys are parameter names and values are parameter value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#set defaults</span>
    <span class="n">default_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_TRAINING_PARAMETERS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">allowed_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">default_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">attributes</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;spectral_target&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;spectral_target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;tolerance&#39;</span><span class="p">])</span><span class="o">/</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;target_steps&#39;</span><span class="p">])</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">allowed_params</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">params</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.bionetwork.SignalingModel.uniform_regularization" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">uniform_regularization</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">,</span> <span class="n">target_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">target_max</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Get the L2 regularization term for deviations of the nodes in Y_full from that of a uniform distribution between 
<code>target_min</code> and <code>target_max</code>. 
Note, this penalizes both deviations from the uniform distribution AND values that are out of range (like a double penalty).</p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.uniform_regularization--parameters">Parameters</h6>
<p>lambda_L2 : float
    scaling factor for state loss
Y_full : torch.Tensor
    the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). 
    Output of BioNet.
target_min : float, optional
    minimum values for nodes in Y_full to take on, by default 0.0
target_max : float, optional
    maximum values for nodes in Y_full to take on, by default 1/<code>self.projection_amplitude_out</code></p>
<h6 id="LEMBAS.model.bionetwork.SignalingModel.uniform_regularization--returns">Returns</h6>
<p>loss : torch.Tensor
    the regularization term</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/bionetwork.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">uniform_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambda_L2</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Y_full</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
                 <span class="n">target_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">target_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the L2 regularization term for deviations of the nodes in Y_full from that of a uniform distribution between </span>
<span class="sd">    `target_min` and `target_max`. </span>
<span class="sd">    Note, this penalizes both deviations from the uniform distribution AND values that are out of range (like a double penalty).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_L2 : float</span>
<span class="sd">        scaling factor for state loss</span>
<span class="sd">    Y_full : torch.Tensor</span>
<span class="sd">        the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). </span>
<span class="sd">        Output of BioNet.</span>
<span class="sd">    target_min : float, optional</span>
<span class="sd">        minimum values for nodes in Y_full to take on, by default 0.0</span>
<span class="sd">    target_max : float, optional</span>
<span class="sd">        maximum values for nodes in Y_full to take on, by default 1/`self.projection_amplitude_out`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : torch.Tensor</span>
<span class="sd">        the regularization term</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lambda_L2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_L2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># loss = lambda_L2 * expected_uniform_distribution(Y_full, target_max = 1/self.projectionAmplitude)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">target_max</span><span class="p">:</span>
        <span class="n">target_max</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">projection_amplitude_out</span>

    <span class="n">sorted_Y_full</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">Y_full</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># sorts each column (signaling network node) in ascending order</span>
    <span class="n">target_distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">target_min</span><span class="p">,</span> <span class="n">target_max</span><span class="p">,</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">dist_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">sorted_Y_full</span> <span class="o">-</span> <span class="n">target_distribution</span><span class="p">))</span> <span class="c1"># difference in distribution</span>
    <span class="n">below_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">target_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">Y_full</span><span class="o">-</span><span class="n">target_min</span><span class="p">))</span> <span class="c1"># those that are below the minimum value</span>
    <span class="n">above_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y_full</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">target_max</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">Y_full</span><span class="o">-</span><span class="n">target_max</span><span class="p">))</span> <span class="c1"># those that are above the maximum value</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">lambda_L2</span><span class="o">*</span><span class="p">(</span><span class="n">dist_loss</span> <span class="o">+</span> <span class="n">below_loss</span> <span class="o">+</span> <span class="n">above_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="LEMBAS.model.model_utilities" class="doc doc-heading">
          <code>model_utilities</code>


</h3>

  <div class="doc doc-contents ">
  
      <p>Helper functions for building the model.</p>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.model_utilities.format_network" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">format_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">weight_label</span><span class="o">=</span><span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> <span class="n">stimulation_label</span><span class="o">=</span><span class="s1">&#39;stimulation&#39;</span><span class="p">,</span> <span class="n">inhibition_label</span><span class="o">=</span><span class="s1">&#39;inhibition&#39;</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Formats the standard network file format to that needed by <code>SignalingModel.parse_network</code></p>
<h6 id="LEMBAS.model.model_utilities.format_network--parameters">Parameters</h6>
<p>net : pd.DataFrame
    signaling network adjacency list with the following columns:
        - <code>weight_label</code>: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0.1). Exclude non-interacting (0) nodes. 
        - <code>stimulation_label</code>: binary whether an interaction is stimulating (1) or [not stimultaing or unknown] (0)
        - <code>inhibition_label</code>: binary whether an interaction is inhibiting (1) or [not inhibiting or unknown] (0)
weight_label : str, optional
    converts <code>stimulation_label</code> and <code>inhibition_label</code> to a single column of stimulating (1), inhibiting (-1), or
    unknown (0.1), by default 'mode_of_action'
stimulation_label : str, optional
    column name of stimulating interactions, see <code>net</code>, by default 'stimulation'
inhibition_label : str, optional
    column name of inhibitory interactions, see <code>net</code>, by default 'inhibition'</p>
<h6 id="LEMBAS.model.model_utilities.format_network--returns">Returns</h6>
<p>formatted_net : pd.DataFrame
    the same dataframe with the additional <code>weight_label</code> column</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/model_utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">format_network</span><span class="p">(</span><span class="n">net</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> 
                   <span class="n">weight_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;mode_of_action&#39;</span><span class="p">,</span> 
                   <span class="n">stimulation_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;stimulation&#39;</span><span class="p">,</span> 
                   <span class="n">inhibition_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;inhibition&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Formats the standard network file format to that needed by `SignalingModel.parse_network`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    net : pd.DataFrame</span>
<span class="sd">        signaling network adjacency list with the following columns:</span>
<span class="sd">            - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0.1). Exclude non-interacting (0) nodes. </span>
<span class="sd">            - `stimulation_label`: binary whether an interaction is stimulating (1) or [not stimultaing or unknown] (0)</span>
<span class="sd">            - `inhibition_label`: binary whether an interaction is inhibiting (1) or [not inhibiting or unknown] (0)</span>
<span class="sd">    weight_label : str, optional</span>
<span class="sd">        converts `stimulation_label` and `inhibition_label` to a single column of stimulating (1), inhibiting (-1), or</span>
<span class="sd">        unknown (0.1), by default &#39;mode_of_action&#39;</span>
<span class="sd">    stimulation_label : str, optional</span>
<span class="sd">        column name of stimulating interactions, see `net`, by default &#39;stimulation&#39;</span>
<span class="sd">    inhibition_label : str, optional</span>
<span class="sd">        column name of inhibitory interactions, see `net`, by default &#39;inhibition&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    formatted_net : pd.DataFrame</span>
<span class="sd">        the same dataframe with the additional `weight_label` column</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">net</span><span class="p">[(</span><span class="n">net</span><span class="p">[</span><span class="n">stimulation_label</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="n">inhibition_label</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;An interaction can either be stimulating (1,0), inhibition (0,1) or unknown (0,0)&#39;</span><span class="p">)</span>

    <span class="n">formatted_net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">formatted_net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">formatted_net</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">formatted_net</span><span class="p">[</span><span class="n">stimulation_label</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">formatted_net</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">formatted_net</span><span class="p">[</span><span class="n">inhibition_label</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">weight_label</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1">#ensuring that lack of known MOA does not imply lack of representation in scipy.sparse.find(A)</span>
    <span class="n">formatted_net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">formatted_net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">formatted_net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">formatted_net</span><span class="p">[</span><span class="n">weight_label</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">formatted_net</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.model_utilities.np_to_torch" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">np_to_torch</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Convert a numpy array to a torch.tensor</p>
<h6 id="LEMBAS.model.model_utilities.np_to_torch--parameters">Parameters</h6>
<p>arr : np.array</p>

<details class="dtype-" open>
  <summary>torch.dtype, optional</summary>
  <p>datatype to store values in torch, by default torch.float32</p>
</details>      <p>device : str
    whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/model_utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">np_to_torch</span><span class="p">(</span><span class="n">arr</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a numpy array to a torch.tensor</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    arr : np.array</span>

<span class="sd">    dtype : torch.dtype, optional</span>
<span class="sd">        datatype to store values in torch, by default torch.float32</span>
<span class="sd">    device : str</span>
<span class="sd">        whether to use gpu (&quot;cuda&quot;) or cpu (&quot;cpu&quot;), by default &quot;cpu&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="LEMBAS.model.train" class="doc doc-heading">
          <code>train</code>


</h3>

  <div class="doc doc-contents ">
  
      <p>Train the signaling model.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h4 id="LEMBAS.model.train.ModelData" class="doc doc-heading">
          <code>ModelData</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.utils.data.Dataset">Dataset</span></code></p>


            <details class="quote">
              <summary>Source code in <code>LEMBAS/model/train.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ModelData</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_in</span><span class="p">,</span> <span class="n">y_out</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span> <span class="o">=</span> <span class="n">X_in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span> <span class="o">=</span> <span class="n">y_out</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="s2">&quot;Returns the total number of samples.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="s2">&quot;Returns one sample of data, data and label (X, y).&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.train.ModelData.__getitem__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__getitem__</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Returns one sample of data, data and label (X, y).</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/train.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="s2">&quot;Returns one sample of data, data and label (X, y).&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h5 id="LEMBAS.model.train.ModelData.__len__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__len__</span><span class="p">()</span></code>

</h5>


  <div class="doc doc-contents ">
  
      <p>Returns the total number of samples.</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/train.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="s2">&quot;Returns the total number of samples.&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>



<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.train.split_data" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">split_data</span><span class="p">(</span><span class="n">X_in</span><span class="p">,</span> <span class="n">y_out</span><span class="p">,</span> <span class="n">train_split_frac</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span> <span class="n">seed</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Splits the data into train, test, and validation.</p>
<h6 id="LEMBAS.model.train.split_data--parameters">Parameters</h6>
<p>X_in : torch.Tensor
    input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). 
y_out : torch.Tensor
    output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF.
train_split_frac : Dict, optional
    fraction of samples to be assigned to each of train, test and split, by default 0.8, 0.2, and 0 respectively
seed : int, optional
    seed value, by default 888</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/train.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">X_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
               <span class="n">y_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
               <span class="n">train_split_frac</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span> 
              <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">888</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Splits the data into train, test, and validation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_in : torch.Tensor</span>
<span class="sd">        input ligand concentrations. Index represents samples and columns represent a ligand. Values represent amount of ligand introduced (e.g., concentration). </span>
<span class="sd">    y_out : torch.Tensor</span>
<span class="sd">        output TF activities. Index represents samples and columns represent TFs. Values represent activity of the TF.</span>
<span class="sd">    train_split_frac : Dict, optional</span>
<span class="sd">        fraction of samples to be assigned to each of train, test and split, by default 0.8, 0.2, and 0 respectively</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        seed value, by default 888</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">train_split_frac</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span><span class="p">]),</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Train-test-validation split must sum to 1&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span> <span class="ow">or</span> <span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_in</span><span class="p">,</span> 
                                                        <span class="n">y_out</span><span class="p">,</span> 
                                                        <span class="n">train_size</span><span class="o">=</span><span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
                                                        <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">_X</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_in</span><span class="p">,</span> 
                                                        <span class="n">y_out</span><span class="p">,</span> 
                                                        <span class="n">train_size</span><span class="o">=</span><span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
                                                        <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">_X</span><span class="p">,</span> 
                                                    <span class="n">_y</span><span class="p">,</span> 
                                                    <span class="n">train_size</span><span class="o">=</span><span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_split_frac</span><span class="p">[</span><span class="s1">&#39;validation&#39;</span><span class="p">]),</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="LEMBAS.model.train.train_signaling_model" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train_signaling_model</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">reset_epoch</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">hyper_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_split_frac</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span> <span class="n">train_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Trains the signaling model</p>
<h6 id="LEMBAS.model.train.train_signaling_model--parameters">Parameters</h6>
<p>mod : SignalingModel
    initialized signaling model. Suggested to also run <code>mod.signaling_network.prescale_weights</code> prior to training
optimizer : torch.optim.adam.Adam
    optimizer to use during training
loss_fn : torch.nn.modules.loss.MSELoss
    loss function to use during training
reset_epoch : int, optional
    number of epochs upon which to reset the optimizer state, by default 200
hyper_params : Dict[str, Union[int, float]], optional
    various hyper parameter inputs for training
        - 'max_iter' : the number of epochs, by default 5000
        - 'learning_rate' : the starting learning rate, by default 2e-3
        - 'batch_size' : number of samples per batch, by default 8
        - 'noise_level' : noise added to signaling network input, by default 10. Set to 0 for no noise. Makes model more robust. 
        - 'gradient_noise_level' : noise added to gradient after backward pass. Makes model more robust. 
        - 'reset_epoch' : number of epochs upon which to reset the optimizer state, by default 200
        - 'param_lambda_L2' : L2 regularization penalty term for most of the model weights and biases
        - 'moa_lambda_L1' : L1 regularization penalty term for incorrect interaction mechanism of action (inhibiting/stimulating)
        - 'ligand_lambda_L2' : L2 regularization penalty term for ligand biases
        - 'uniform_lambda_L2' : L2 regularization penalty term for 
        - 'uniform_max' : 
        - 'spectral_loss_factor' : regularization penalty term for 
        - 'n_probes_spectral' : 
        - 'power_steps_spectral' : 
        - 'subset_n_spectral' : 
train_split_frac : Dict, optional
    fraction of samples to be assigned to each of train, test and split, by default 0.8, 0.2, and 0 respectively
train_seed : int, optional
    seed value, by default mod.seed. By explicitly making this an argument, it allows different train-test splits even 
    with the same mod.seed, e.g., for cross-validation
verbose : bool, optional
    whether to print various progress stats across training epochs</p>
<h6 id="LEMBAS.model.train.train_signaling_model--returns">Returns</h6>
<p>mod : SignalingModel
    a copy of the input model with trained parameters
cur_loss : List[float], optional
    a list of the loss (excluding regularizations) across training iterations
cur_eig : List[float], optional
    a list of the spectral_radius across training iterations
mean_loss : torch.Tensor
    mean TF activity loss across samples (independent of training)
X_train : torch.Tensor
    the train split of the input data
X_test : torch.Tensor
    the test split of the input data
X_val : torch.Tensor
    the validation split of the input data
y_train : torch.Tensor
    the train split of the output data
y_test : torch.Tensor
    the test split of the output data
y_val : torch.Tensor
    the validation split of the output data</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/model/train.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_signaling_model</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span>  
                          <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> 
                          <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
                          <span class="n">reset_epoch</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
                          <span class="n">hyper_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                          <span class="n">train_split_frac</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
                          <span class="n">train_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Trains the signaling model</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mod : SignalingModel</span>
<span class="sd">        initialized signaling model. Suggested to also run `mod.signaling_network.prescale_weights` prior to training</span>
<span class="sd">    optimizer : torch.optim.adam.Adam</span>
<span class="sd">        optimizer to use during training</span>
<span class="sd">    loss_fn : torch.nn.modules.loss.MSELoss</span>
<span class="sd">        loss function to use during training</span>
<span class="sd">    reset_epoch : int, optional</span>
<span class="sd">        number of epochs upon which to reset the optimizer state, by default 200</span>
<span class="sd">    hyper_params : Dict[str, Union[int, float]], optional</span>
<span class="sd">        various hyper parameter inputs for training</span>
<span class="sd">            - &#39;max_iter&#39; : the number of epochs, by default 5000</span>
<span class="sd">            - &#39;learning_rate&#39; : the starting learning rate, by default 2e-3</span>
<span class="sd">            - &#39;batch_size&#39; : number of samples per batch, by default 8</span>
<span class="sd">            - &#39;noise_level&#39; : noise added to signaling network input, by default 10. Set to 0 for no noise. Makes model more robust. </span>
<span class="sd">            - &#39;gradient_noise_level&#39; : noise added to gradient after backward pass. Makes model more robust. </span>
<span class="sd">            - &#39;reset_epoch&#39; : number of epochs upon which to reset the optimizer state, by default 200</span>
<span class="sd">            - &#39;param_lambda_L2&#39; : L2 regularization penalty term for most of the model weights and biases</span>
<span class="sd">            - &#39;moa_lambda_L1&#39; : L1 regularization penalty term for incorrect interaction mechanism of action (inhibiting/stimulating)</span>
<span class="sd">            - &#39;ligand_lambda_L2&#39; : L2 regularization penalty term for ligand biases</span>
<span class="sd">            - &#39;uniform_lambda_L2&#39; : L2 regularization penalty term for </span>
<span class="sd">            - &#39;uniform_max&#39; : </span>
<span class="sd">            - &#39;spectral_loss_factor&#39; : regularization penalty term for </span>
<span class="sd">            - &#39;n_probes_spectral&#39; : </span>
<span class="sd">            - &#39;power_steps_spectral&#39; : </span>
<span class="sd">            - &#39;subset_n_spectral&#39; : </span>
<span class="sd">    train_split_frac : Dict, optional</span>
<span class="sd">        fraction of samples to be assigned to each of train, test and split, by default 0.8, 0.2, and 0 respectively</span>
<span class="sd">    train_seed : int, optional</span>
<span class="sd">        seed value, by default mod.seed. By explicitly making this an argument, it allows different train-test splits even </span>
<span class="sd">        with the same mod.seed, e.g., for cross-validation</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        whether to print various progress stats across training epochs</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mod : SignalingModel</span>
<span class="sd">        a copy of the input model with trained parameters</span>
<span class="sd">    cur_loss : List[float], optional</span>
<span class="sd">        a list of the loss (excluding regularizations) across training iterations</span>
<span class="sd">    cur_eig : List[float], optional</span>
<span class="sd">        a list of the spectral_radius across training iterations</span>
<span class="sd">    mean_loss : torch.Tensor</span>
<span class="sd">        mean TF activity loss across samples (independent of training)</span>
<span class="sd">    X_train : torch.Tensor</span>
<span class="sd">        the train split of the input data</span>
<span class="sd">    X_test : torch.Tensor</span>
<span class="sd">        the test split of the input data</span>
<span class="sd">    X_val : torch.Tensor</span>
<span class="sd">        the validation split of the input data</span>
<span class="sd">    y_train : torch.Tensor</span>
<span class="sd">        the train split of the output data</span>
<span class="sd">    y_test : torch.Tensor</span>
<span class="sd">        the test split of the output data</span>
<span class="sd">    y_val : torch.Tensor</span>
<span class="sd">        the validation split of the output data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">hyper_params</span><span class="p">:</span>
        <span class="n">hyper_params</span> <span class="o">=</span> <span class="n">HYPER_PARAMS</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hyper_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="p">{</span><span class="o">**</span><span class="n">HYPER_PARAMS</span><span class="p">,</span> <span class="o">**</span><span class="n">hyper_params</span><span class="p">}</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">HYPER_PARAMS</span><span class="p">}</span> <span class="c1"># give user input priority</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">initialize_progress</span><span class="p">(</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">])</span>

    <span class="n">mod</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># do not overwrite input</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">reset_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">X_in</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">df_to_tensor</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">X_in</span><span class="p">)</span>
    <span class="n">y_out</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">df_to_tensor</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">y_out</span><span class="p">)</span>
    <span class="n">mean_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y_out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">y_out</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">y_out</span><span class="p">)</span> <span class="c1"># mean TF (across samples) loss</span>

    <span class="c1"># set up data objects</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">train_seed</span><span class="p">:</span>
        <span class="n">train_seed</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">seed</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">X_in</span><span class="p">,</span> <span class="n">y_out</span><span class="p">,</span> <span class="n">train_split_frac</span><span class="p">,</span> <span class="n">train_seed</span><span class="p">)</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">ModelData</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
        <span class="n">pin_memory</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pin_memory</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># if n_cores != 0:</span>
    <span class="c1">#     n_cores_train = min(n_cores, hyper_params[&#39;batch_size&#39;])</span>
    <span class="c1"># else:</span>
    <span class="c1">#     n_cores_train = n_cores</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
                                  <span class="c1"># num_workers=n_cores_train,</span>
                                  <span class="n">drop_last</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                  <span class="n">pin_memory</span> <span class="o">=</span> <span class="n">pin_memory</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># begin iteration</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">]):</span>
        <span class="c1"># set learning rate</span>
        <span class="n">cur_lr</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_lr</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;max_iter&#39;</span><span class="p">],</span> <span class="n">max_height</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">],</span>
                              <span class="n">start_height</span><span class="o">=</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">end_height</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">peak</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cur_lr</span>

        <span class="n">cur_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cur_eig</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># iterate through batches</span>
        <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_seeds</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="n">e</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X_in_</span><span class="p">,</span> <span class="n">y_out_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
            <span class="n">mod</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">X_in_</span><span class="p">,</span> <span class="n">y_out_</span> <span class="o">=</span> <span class="n">X_in_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">y_out_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># forward pass</span>
            <span class="n">X_full</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">X_in_</span><span class="p">)</span> <span class="c1"># transform to full network with ligand input concentrations</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_seeds</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="n">mod</span><span class="o">.</span><span class="n">_gradient_seed_counter</span><span class="p">)</span>
            <span class="n">network_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">X_full</span> <span class="o">=</span> <span class="n">X_full</span> <span class="o">+</span> <span class="p">(</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;noise_level&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">cur_lr</span> <span class="o">*</span> <span class="n">network_noise</span><span class="p">)</span> <span class="c1"># randomly add noise to signaling network input, makes model more robust</span>
            <span class="n">Y_full</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">signaling_network</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span> <span class="c1"># train signaling network weights</span>
            <span class="n">Y_hat</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">Y_full</span><span class="p">)</span>

            <span class="c1"># get prediction loss</span>
            <span class="n">fit_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_out_</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">)</span>

            <span class="c1"># get regularization losses</span>
            <span class="n">sign_reg</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">sign_regularization</span><span class="p">(</span><span class="n">lambda_L1</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;moa_lambda_L1&#39;</span><span class="p">])</span> <span class="c1"># incorrect MoA</span>
            <span class="n">ligand_reg</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">ligand_regularization</span><span class="p">(</span><span class="n">lambda_L2</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;ligand_lambda_L2&#39;</span><span class="p">])</span> <span class="c1"># ligand biases</span>
            <span class="n">stability_loss</span><span class="p">,</span> <span class="n">spectral_radius</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">get_SS_loss</span><span class="p">(</span><span class="n">Y_full</span> <span class="o">=</span> <span class="n">Y_full</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">spectral_loss_factor</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;spectral_loss_factor&#39;</span><span class="p">],</span>
                                                                                <span class="n">subset_n</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;subset_n_spectral&#39;</span><span class="p">],</span> <span class="n">n_probes</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;n_probes_spectral&#39;</span><span class="p">],</span> 
                                                                                <span class="n">power_steps</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;power_steps_spectral&#39;</span><span class="p">])</span>
            <span class="n">uniform_reg</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">uniform_regularization</span><span class="p">(</span><span class="n">lambda_L2</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;uniform_lambda_L2&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">cur_lr</span><span class="p">,</span> <span class="n">Y_full</span> <span class="o">=</span> <span class="n">Y_full</span><span class="p">,</span> 
                                                     <span class="n">target_min</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">target_max</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;uniform_max&#39;</span><span class="p">])</span> <span class="c1"># uniform distribution</span>
            <span class="n">param_reg</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">L2_reg</span><span class="p">(</span><span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;param_lambda_L2&#39;</span><span class="p">])</span> <span class="c1"># all model weights and signaling network biases</span>

            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">fit_loss</span> <span class="o">+</span> <span class="n">sign_reg</span> <span class="o">+</span> <span class="n">ligand_reg</span> <span class="o">+</span> <span class="n">param_reg</span> <span class="o">+</span> <span class="n">stability_loss</span> <span class="o">+</span> <span class="n">uniform_reg</span>

            <span class="c1"># gradient</span>
            <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">mod</span><span class="o">.</span><span class="n">add_gradient_noise</span><span class="p">(</span><span class="n">noise_level</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="s1">&#39;gradient_noise_level&#39;</span><span class="p">])</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># store</span>
            <span class="n">cur_eig</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">spectral_radius</span><span class="p">)</span>
            <span class="n">cur_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fit_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">update_progress</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="nb">iter</span> <span class="o">=</span> <span class="n">e</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">cur_loss</span><span class="p">,</span> <span class="n">eig</span> <span class="o">=</span> <span class="n">cur_eig</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">cur_lr</span><span class="p">,</span> 
                                     <span class="n">n_sign_mismatches</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">signaling_network</span><span class="o">.</span><span class="n">count_sign_mismatch</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">250</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">print_stats</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="nb">iter</span> <span class="o">=</span> <span class="n">e</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">e</span> <span class="o">%</span> <span class="n">reset_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">e</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">reset_state</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">mins</span><span class="p">,</span> <span class="n">secs</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training ran in: </span><span class="si">{:.0f}</span><span class="s2"> min </span><span class="si">{:.2f}</span><span class="s2"> sec&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mins</span><span class="p">,</span> <span class="n">secs</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mod</span><span class="p">,</span> <span class="n">cur_loss</span><span class="p">,</span> <span class="n">cur_eig</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">stats</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>


  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="LEMBAS.plotting" class="doc doc-heading">
          <code>plotting</code>


</h2>

  <div class="doc doc-contents ">
  
      <p>Helper functions for data visualization.</p>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="LEMBAS.plotting.shade_plot" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">shade_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">x_label</span><span class="p">,</span> <span class="n">y_label</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p><em>summary</em></p>
<h5 id="LEMBAS.plotting.shade_plot--parameters">Parameters</h5>
<p>X : np.array
    x axis values
Y : np.array
    y axis values
sigma : np.array
    standard deviation of y axis values
x_label : str
    x axis label 
y_label : str
    y axis label</p>
<h5 id="LEMBAS.plotting.shade_plot--returns">Returns</h5>
<p>plot : plotnine.ggplot.ggplot
    <em>description</em></p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/plotting.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">shade_plot</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">sigma</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">x_label</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">y_label</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
              <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : np.array</span>
<span class="sd">        x axis values</span>
<span class="sd">    Y : np.array</span>
<span class="sd">        y axis values</span>
<span class="sd">    sigma : np.array</span>
<span class="sd">        standard deviation of y axis values</span>
<span class="sd">    x_label : str</span>
<span class="sd">        x axis label </span>
<span class="sd">    y_label : str</span>
<span class="sd">        y axis label</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    plot : plotnine.ggplot.ggplot</span>
<span class="sd">        _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">x_label</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_label</span><span class="p">:</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;sigma&#39;</span><span class="p">:</span> <span class="n">sigma</span>
    <span class="p">})</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sigma_min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">y_label</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">sigma</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sigma_max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">y_label</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="o">.</span><span class="n">sigma</span>

    <span class="n">plot</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">p9</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">p9</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_label</span><span class="p">))</span> <span class="o">+</span>
        <span class="n">p9</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">p9</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_label</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;#1E90FF&#39;</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">p9</span><span class="o">.</span><span class="n">geom_ribbon</span><span class="p">(</span><span class="n">p9</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y_label</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">=</span> <span class="s1">&#39;sigma_min&#39;</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="s1">&#39;sigma_max&#39;</span><span class="p">),</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">p9</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span> <span class="o">+</span>
        <span class="c1"># p9.ylim(10**min_log, round(data[y_label].max(), 1)) +</span>
        <span class="c1"># p9.scale_y_log10() + </span>
        <span class="n">p9</span><span class="o">.</span><span class="n">theme_bw</span><span class="p">()</span> <span class="o">+</span> 
        <span class="n">p9</span><span class="o">.</span><span class="n">theme</span><span class="p">(</span><span class="n">figure_size</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">plot</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="LEMBAS.utilities" class="doc doc-heading">
          <code>utilities</code>


</h2>

  <div class="doc doc-contents ">
  
      <p>Helper functions for running and training the SignalingModel.</p>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.get_lr" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_lr</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">max_height</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">start_height</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">end_height</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">peak</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Calculates learning rate for a given iteration during training.</p>
<h5 id="LEMBAS.utilities.get_lr--parameters">Parameters</h5>
<p>iter : int
    the current iteration
max_iter : int
    the maximum number of training iterations
max_height : float, optional
    tuning parameters for learning for the first 95% of iterations, by default 1e-3
start_height : float, optional
    tuning parameter for learning rate before peak iterations, by default 1e-5
end_height : float, optional
    tuning parameter for learning rate afer peak iterations, by default 1e-5
peak : int, optional
    the first # of iterations to calculate lr on (should be less than 95% 
    of max_iter), by default 1000</p>
<h5 id="LEMBAS.utilities.get_lr--returns">Returns</h5>
<p>lr : float
    the learning rate</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="nb">iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_height</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> 
             <span class="n">start_height</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end_height</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> 
             <span class="n">peak</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates learning rate for a given iteration during training.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    iter : int</span>
<span class="sd">        the current iteration</span>
<span class="sd">    max_iter : int</span>
<span class="sd">        the maximum number of training iterations</span>
<span class="sd">    max_height : float, optional</span>
<span class="sd">        tuning parameters for learning for the first 95% of iterations, by default 1e-3</span>
<span class="sd">    start_height : float, optional</span>
<span class="sd">        tuning parameter for learning rate before peak iterations, by default 1e-5</span>
<span class="sd">    end_height : float, optional</span>
<span class="sd">        tuning parameter for learning rate afer peak iterations, by default 1e-5</span>
<span class="sd">    peak : int, optional</span>
<span class="sd">        the first # of iterations to calculate lr on (should be less than 95% </span>
<span class="sd">        of max_iter), by default 1000</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lr : float</span>
<span class="sd">        the learning rate</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">phase_length</span> <span class="o">=</span> <span class="mf">0.95</span> <span class="o">*</span> <span class="n">max_iter</span>
    <span class="k">if</span> <span class="nb">iter</span><span class="o">&lt;=</span><span class="n">peak</span><span class="p">:</span>
        <span class="n">effective_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="o">/</span><span class="n">peak</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_height</span><span class="o">-</span><span class="n">start_height</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">effective_iter</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">start_height</span>
    <span class="k">elif</span> <span class="nb">iter</span><span class="o">&lt;=</span><span class="n">phase_length</span><span class="p">:</span>
        <span class="n">effective_iter</span> <span class="o">=</span> <span class="p">(</span><span class="nb">iter</span><span class="o">-</span><span class="n">peak</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">phase_length</span><span class="o">-</span><span class="n">peak</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_height</span><span class="o">-</span><span class="n">end_height</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">effective_iter</span><span class="o">+</span><span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">end_height</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">end_height</span>
    <span class="k">return</span> <span class="n">lr</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.get_moving_average" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_moving_average</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Get the moving average of a tracked state across n_steps. Serves to smooth value. </p>
<h5 id="LEMBAS.utilities.get_moving_average--parameters">Parameters</h5>
<p>values : np.array
    values on which to get the moving average
n_steps : int
    number of steps across which to get the moving average</p>
<h5 id="LEMBAS.utilities.get_moving_average--returns">Returns</h5>
<p>moving_average : np.array
    the moving average across values</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_moving_average</span><span class="p">(</span><span class="n">values</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the moving average of a tracked state across n_steps. Serves to smooth value. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    values : np.array</span>
<span class="sd">        values on which to get the moving average</span>
<span class="sd">    n_steps : int</span>
<span class="sd">        number of steps across which to get the moving average</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    moving_average : np.array</span>
<span class="sd">        the moving average across values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">moving_average</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">((</span><span class="n">i</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_steps</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_steps</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">moving_average</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">moving_average</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.initialize_progress" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">initialize_progress</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Track various stats of the progress of training the model.</p>
<h5 id="LEMBAS.utilities.initialize_progress--parameters">Parameters</h5>
<p>max_iter : int
    the maximum number of training iterations</p>
<h5 id="LEMBAS.utilities.initialize_progress--returns">Returns</h5>
<p>stats : dict
    a dictionary of progress statistics</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_progress</span><span class="p">(</span><span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Track various stats of the progress of training the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    max_iter : int</span>
<span class="sd">        the maximum number of training iterations</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    stats : dict</span>
<span class="sd">        a dictionary of progress statistics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;start_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;end_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;iter_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>

    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_sigma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_sigma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>

    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;violations&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.print_stats" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">print_stats</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="nb">iter</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Prints various stats of the progress of training the model.</p>
<h5 id="LEMBAS.utilities.print_stats--parameters">Parameters</h5>
<p>stats : dict
    a dictionary of progress statistics
iter : int
    the current training iteration</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="nb">iter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prints various stats of the progress of training the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    stats : dict</span>
<span class="sd">        a dictionary of progress statistics</span>
<span class="sd">    iter : int</span>
<span class="sd">        the current training iteration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;i=</span><span class="si">{:.0f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;, l=</span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">])</span>
    <span class="c1"># if not np.isnan(stats[&#39;test&#39;][iter]):</span>
    <span class="c1">#     msg += &#39;, t={:.5f}&#39;.format(stats[&#39;test&#39;][iter])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;, s=</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;, r=</span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;violations&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;, v=</span><span class="si">{:.0f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;violations&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.set_cores" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_cores</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Set environmental variables to ensure core usage is limited to n_cores</p>
<h5 id="LEMBAS.utilities.set_cores--parameters">Parameters</h5>
<p>n_cores : int
    number of cores to use</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_cores</span><span class="p">(</span><span class="n">n_cores</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set environmental variables to ensure core usage is limited to n_cores</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_cores : int</span>
<span class="sd">        number of cores to use</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OMP_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MKL_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENBLAS_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;VECLIB_MAXIMUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;NUMEXPR_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_cores</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.set_seeds" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">set_seeds</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Sets random seeds for torch operations.</p>
<h5 id="LEMBAS.utilities.set_seeds--parameters">Parameters</h5>
<p>seed : int, optional
    seed value, by default 888</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_seeds</span><span class="p">(</span><span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">888</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sets random seeds for torch operations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        seed value, by default 888</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;CUBLAS_WORKSPACE_CONFIG&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUBLAS_WORKSPACE_CONFIG&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;:4096:8&#39;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="LEMBAS.utilities.update_progress" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">update_progress</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eig</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_sign_mismatches</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Updates various stats of the progress of training the model.</p>
<h5 id="LEMBAS.utilities.update_progress--parameters">Parameters</h5>
<p>stats : dict
    a dictionary of progress statistics
iter : int
    the current training iteration
loss : List[float], optional
    a list of the loss (excluding regularizations) up to <code>iter</code> , by default None
eig : List[float], optional
    a list of the spectral_radius up to <code>iter</code> , by default None
learning_rate : float, optional
    the model learning rate at <code>iter</code>, by default None
n_sign_mismatches : float, optional
    the total number of sign mismatches at <code>iter</code>, 
    output of <code>SignalingModel.signaling_network.count_sign_mismatch()</code>, by default None</p>
<h5 id="LEMBAS.utilities.update_progress--returns">Returns</h5>
<p>stats : dict
    updated dictionary of progress statistics</p>

          <details class="quote">
            <summary>Source code in <code>LEMBAS/utilities.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update_progress</span><span class="p">(</span><span class="n">stats</span> <span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                  <span class="n">loss</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eig</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                  <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_sign_mismatches</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates various stats of the progress of training the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    stats : dict</span>
<span class="sd">        a dictionary of progress statistics</span>
<span class="sd">    iter : int</span>
<span class="sd">        the current training iteration</span>
<span class="sd">    loss : List[float], optional</span>
<span class="sd">        a list of the loss (excluding regularizations) up to `iter` , by default None</span>
<span class="sd">    eig : List[float], optional</span>
<span class="sd">        a list of the spectral_radius up to `iter` , by default None</span>
<span class="sd">    learning_rate : float, optional</span>
<span class="sd">        the model learning rate at `iter`, by default None</span>
<span class="sd">    n_sign_mismatches : float, optional</span>
<span class="sd">        the total number of sign mismatches at `iter`, </span>
<span class="sd">        output of `SignalingModel.signaling_network.count_sign_mismatch()`, by default None</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    stats : dict</span>
<span class="sd">        updated dictionary of progress statistics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss_sigma&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">eig</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_mean&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">eig</span><span class="p">))</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;eig_sigma&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">eig</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">learning_rate</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="k">if</span> <span class="n">n_sign_mismatches</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;violations&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_sign_mismatches</span>

    <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;iter_time&#39;</span><span class="p">][</span><span class="nb">iter</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>


  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../macrophage_example/" class="btn btn-neutral float-left" title="Tutorial"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../macrophage_example/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
